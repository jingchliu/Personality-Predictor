{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/Jo/anaconda3/envs/PythonData/lib/python3.6/site-packages (0.14.0)\r\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df = pd.read_csv(\"Resources/mbti_1.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "mbti_df = mbti_df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "mbti_df = mbti_df.dropna()\n",
    "mbti_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_row(row):\n",
    "    l = []\n",
    "    for i in row.split('|||'):\n",
    "        l.append(len(i.split()))\n",
    "    return np.var(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>description</th>\n",
       "      <th>words_per_comment</th>\n",
       "      <th>squared_total_words</th>\n",
       "      <th>word_count_variance_per_comment</th>\n",
       "      <th>interrobangs_per_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>Introvert Intuition Feeling Judging</td>\n",
       "      <td>11.12</td>\n",
       "      <td>22.24</td>\n",
       "      <td>135.2900</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>Extrovert Intuition Thinking Perceiving</td>\n",
       "      <td>23.40</td>\n",
       "      <td>46.80</td>\n",
       "      <td>187.4756</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>Introvert Intuition Thinking Perceiving</td>\n",
       "      <td>16.72</td>\n",
       "      <td>33.44</td>\n",
       "      <td>180.6900</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>Introvert Intuition Thinking Judging</td>\n",
       "      <td>21.28</td>\n",
       "      <td>42.56</td>\n",
       "      <td>181.8324</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>Extrovert Intuition Thinking Judging</td>\n",
       "      <td>19.34</td>\n",
       "      <td>38.68</td>\n",
       "      <td>196.4576</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  \\\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...   \n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...   \n",
       "\n",
       "                               description  words_per_comment  \\\n",
       "0      Introvert Intuition Feeling Judging              11.12   \n",
       "1  Extrovert Intuition Thinking Perceiving              23.40   \n",
       "2  Introvert Intuition Thinking Perceiving              16.72   \n",
       "3     Introvert Intuition Thinking Judging              21.28   \n",
       "4     Extrovert Intuition Thinking Judging              19.34   \n",
       "\n",
       "   squared_total_words  word_count_variance_per_comment  \\\n",
       "0                22.24                         135.2900   \n",
       "1                46.80                         187.4756   \n",
       "2                33.44                         180.6900   \n",
       "3                42.56                         181.8324   \n",
       "4                38.68                         196.4576   \n",
       "\n",
       "   interrobangs_per_comment  \n",
       "0                      0.42  \n",
       "1                      0.10  \n",
       "2                      0.32  \n",
       "3                      0.28  \n",
       "4                      0.22  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti = {'I':'Introvert', 'E':'Extrovert', 'N':'Intuition', \n",
    "        'S':'Sensing', 'T':'Thinking', 'F': 'Feeling', \n",
    "        'J':'Judging', 'P': 'Perceiving'}\n",
    "#description of the type \n",
    "mbti_df['description'] = mbti_df['type'].apply(lambda x: ' '.join([mbti[l] for l in list(x)]))\n",
    "#words per comment\n",
    "mbti_df['words_per_comment'] = mbti_df['posts'].apply(lambda x: len(x.split())/50)\n",
    "#squared totals\n",
    "mbti_df['squared_total_words'] = mbti_df['words_per_comment']*2\n",
    "#word count variance\n",
    "mbti_df['word_count_variance_per_comment'] = mbti_df['posts'].apply(lambda x: var_row(x))\n",
    "#interrobangs per comment = \n",
    "mbti_df['interrobangs_per_comment']=mbti_df['posts'].apply(lambda x: x.count('?')/50) + mbti_df['posts'].apply(lambda x: x.count('!')/50)\n",
    "#preview\n",
    "mbti_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>description</th>\n",
       "      <th>words_per_comment</th>\n",
       "      <th>squared_total_words</th>\n",
       "      <th>word_count_variance_per_comment</th>\n",
       "      <th>interrobangs_per_comment</th>\n",
       "      <th>i_e</th>\n",
       "      <th>n_s</th>\n",
       "      <th>f_t</th>\n",
       "      <th>j_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>Introvert Intuition Feeling Judging</td>\n",
       "      <td>11.12</td>\n",
       "      <td>22.24</td>\n",
       "      <td>135.2900</td>\n",
       "      <td>0.42</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>Extrovert Intuition Thinking Perceiving</td>\n",
       "      <td>23.40</td>\n",
       "      <td>46.80</td>\n",
       "      <td>187.4756</td>\n",
       "      <td>0.10</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>Introvert Intuition Thinking Perceiving</td>\n",
       "      <td>16.72</td>\n",
       "      <td>33.44</td>\n",
       "      <td>180.6900</td>\n",
       "      <td>0.32</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>Introvert Intuition Thinking Judging</td>\n",
       "      <td>21.28</td>\n",
       "      <td>42.56</td>\n",
       "      <td>181.8324</td>\n",
       "      <td>0.28</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>Extrovert Intuition Thinking Judging</td>\n",
       "      <td>19.34</td>\n",
       "      <td>38.68</td>\n",
       "      <td>196.4576</td>\n",
       "      <td>0.22</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  \\\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...   \n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...   \n",
       "\n",
       "                               description  words_per_comment  \\\n",
       "0      Introvert Intuition Feeling Judging              11.12   \n",
       "1  Extrovert Intuition Thinking Perceiving              23.40   \n",
       "2  Introvert Intuition Thinking Perceiving              16.72   \n",
       "3     Introvert Intuition Thinking Judging              21.28   \n",
       "4     Extrovert Intuition Thinking Judging              19.34   \n",
       "\n",
       "   squared_total_words  word_count_variance_per_comment  \\\n",
       "0                22.24                         135.2900   \n",
       "1                46.80                         187.4756   \n",
       "2                33.44                         180.6900   \n",
       "3                42.56                         181.8324   \n",
       "4                38.68                         196.4576   \n",
       "\n",
       "   interrobangs_per_comment i_e n_s f_t j_p  \n",
       "0                      0.42   I   N   F   J  \n",
       "1                      0.10   E   N   T   P  \n",
       "2                      0.32   I   N   T   P  \n",
       "3                      0.28   I   N   T   J  \n",
       "4                      0.22   E   N   T   J  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df['i_e']= mbti_df['type'].astype(str).str[0]\n",
    "mbti_df['n_s']= mbti_df['type'].astype(str).str[1]\n",
    "mbti_df['f_t']= mbti_df['type'].astype(str).str[2]\n",
    "mbti_df['j_p']= mbti_df['type'].astype(str).str[3]\n",
    "mbti_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_df.to_csv('Resources/mbti.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Target String Setting\n",
    "target_string = mbti_df['posts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9877\n"
     ]
    }
   ],
   "source": [
    "compound = analyzer.polarity_scores(target_string)[\"compound\"]\n",
    "print(compound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'posts', 'description', 'words_per_comment',\n",
       "       'squared_total_words', 'word_count_variance_per_comment',\n",
       "       'interrobangs_per_comment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features = mbti_df[['words_per_comment','squared_total_words','squared_total_words','interrobangs_per_comment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = mbti_df[\"type\"]\n",
    "target_names = [\"INFJ\",\"INFP\",\"INTJ\",'INTP',\"ISFJ\",\"ISFP\",\"ISTJ\",'ISTP',\"ENFJ\",\"ENFP\",\"ENTJ\",'ENTP',\"ESFJ\",\"ESFP\",\"ESTJ\",'ESTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words_per_comment</th>\n",
       "      <th>squared_total_words</th>\n",
       "      <th>squared_total_words</th>\n",
       "      <th>interrobangs_per_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>28.22</td>\n",
       "      <td>56.44</td>\n",
       "      <td>56.44</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>20.92</td>\n",
       "      <td>41.84</td>\n",
       "      <td>41.84</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>25.90</td>\n",
       "      <td>51.80</td>\n",
       "      <td>51.80</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>30.04</td>\n",
       "      <td>60.08</td>\n",
       "      <td>60.08</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>28.98</td>\n",
       "      <td>57.96</td>\n",
       "      <td>57.96</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      words_per_comment  squared_total_words  squared_total_words  \\\n",
       "2706              28.22                56.44                56.44   \n",
       "2521              20.92                41.84                41.84   \n",
       "4192              25.90                51.80                51.80   \n",
       "6296              30.04                60.08                60.08   \n",
       "3399              28.98                57.96                57.96   \n",
       "\n",
       "      interrobangs_per_comment  \n",
       "2706                      1.14  \n",
       "2521                      0.24  \n",
       "4192                      0.74  \n",
       "6296                      0.16  \n",
       "3399                      0.60  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.2085766984322164\n",
      "Testing Data Score: 0.218994928538497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "\n",
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        INFJ       0.00      0.00      0.00        49\n",
      "        INFP       0.00      0.00      0.00       160\n",
      "        INTJ       0.00      0.00      0.00        51\n",
      "        INTP       0.00      0.00      0.00       165\n",
      "        ISFJ       0.00      0.00      0.00         8\n",
      "        ISFP       0.00      0.00      0.00         8\n",
      "        ISTJ       0.00      0.00      0.00        12\n",
      "        ISTP       0.00      0.00      0.00        20\n",
      "        ENFJ       0.00      0.00      0.00       361\n",
      "        ENFP       0.22      1.00      0.36       475\n",
      "        ENTJ       0.00      0.00      0.00       251\n",
      "        ENTP       0.00      0.00      0.00       350\n",
      "        ESFJ       0.00      0.00      0.00        54\n",
      "        ESFP       0.00      0.00      0.00        64\n",
      "        ESTJ       0.00      0.00      0.00        56\n",
      "        ESTP       0.00      0.00      0.00        85\n",
      "\n",
      "    accuracy                           0.22      2169\n",
      "   macro avg       0.01      0.06      0.02      2169\n",
      "weighted avg       0.05      0.22      0.08      2169\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jo/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(classification_report(encoded_y_test, predictions,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test for I vs. E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data I_E Score: 0.7654472794343683\n",
      "Testing Data I_E Score: 0.7819271553711388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Introvert       0.00      0.00      0.00       473\n",
      "   Extrovert       0.78      1.00      0.88      1696\n",
      "\n",
      "    accuracy                           0.78      2169\n",
      "   macro avg       0.39      0.50      0.44      2169\n",
      "weighted avg       0.61      0.78      0.69      2169\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jo/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "target = mbti_df[\"i_e\"]\n",
    "target_names = [\"Introvert\",\"Extrovert\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "\n",
    "print(f\"Training Data I_E Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data I_E Score: {model.score(X_test_scaled, encoded_y_test)}\")\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(classification_report(encoded_y_test, predictions,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test for N vs. S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data N_S Score: 0.8632031970488779\n",
      "Testing Data N_S Score: 0.8584601198709082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Intuition       0.86      1.00      0.92      1862\n",
      "     Sensing       0.00      0.00      0.00       307\n",
      "\n",
      "    accuracy                           0.86      2169\n",
      "   macro avg       0.43      0.50      0.46      2169\n",
      "weighted avg       0.74      0.86      0.79      2169\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jo/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "target = mbti_df[\"n_s\"]\n",
    "target_names = [\"Intuition\",\"Sensing\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "\n",
    "print(f\"Training Data N_S Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data N_S Score: {model.score(X_test_scaled, encoded_y_test)}\")\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(classification_report(encoded_y_test, predictions,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test for F vs. T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data F_T Score: 0.5579465109130034\n",
      "Testing Data F_T Score: 0.553711387736284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Feeling       0.56      0.86      0.68      1179\n",
      "    Thinking       0.53      0.19      0.28       990\n",
      "\n",
      "    accuracy                           0.55      2169\n",
      "   macro avg       0.54      0.52      0.48      2169\n",
      "weighted avg       0.55      0.55      0.49      2169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = mbti_df[\"f_t\"]\n",
    "target_names = [\"Feeling\",\"Thinking\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "\n",
    "print(f\"Training Data F_T Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data F_T Score: {model.score(X_test_scaled, encoded_y_test)}\")\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(classification_report(encoded_y_test, predictions,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test for J vs. P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data J_P Score: 0.6015985244389794\n",
      "Testing Data J_P Score: 0.611802674043338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Judging       0.00      0.00      0.00       842\n",
      "  Perceiving       0.61      1.00      0.76      1327\n",
      "\n",
      "    accuracy                           0.61      2169\n",
      "   macro avg       0.31      0.50      0.38      2169\n",
      "weighted avg       0.37      0.61      0.46      2169\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jo/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "target = mbti_df[\"j_p\"]\n",
    "target_names = [\"Judging\",\"Perceiving\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "\n",
    "print(f\"Training Data J_P Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data J_P Score: {model.score(X_test_scaled, encoded_y_test)}\")\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(classification_report(encoded_y_test, predictions,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "              'gamma': [0.0001, 0.001, 0.01]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jo/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.602, total=   0.3s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.602, total=   0.3s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.601, total=   0.3s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.602, total=   0.3s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.602, total=   0.3s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.601, total=   0.3s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.602, total=   0.3s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.602, total=   0.3s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.601, total=   0.3s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.602, total=   0.4s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.602, total=   0.4s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.601, total=   0.3s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.602, total=   0.4s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.602, total=   0.4s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.601, total=   0.3s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.602, total=   0.4s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.602, total=   0.4s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.601, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.602, total=   0.4s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.602, total=   0.4s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.601, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.602, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.602, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.601, total=   0.4s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.602, total=   0.4s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.602, total=   0.4s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.601, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    9.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='linear',\n",
       "                           max_iter=-1, probability=False, random_state=None,\n",
       "                           shrinking=True, tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train_scaled, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.0001}\n",
      "0.6015985244389794\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multi-label binary indicator input with different numbers of labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-4e3fd7615092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_categorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m         \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     86\u001b[0m             len(set(check_array(y, ['csr', 'csc', 'coo']).shape[1]\n\u001b[1;32m     87\u001b[0m                     for y in ys)) > 1):\n\u001b[0;32m---> 88\u001b[0;31m         raise ValueError(\"Multi-label binary indicator input with \"\n\u001b[0m\u001b[1;32m     89\u001b[0m                          \"different numbers of labels\")\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Multi-label binary indicator input with different numbers of labels"
     ]
    }
   ],
   "source": [
    "predictions = grid.predict(X_test_scaled)\n",
    "predictions=to_categorical(predictions)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_categorical, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM.sav']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "filename = 'SVM.sav'\n",
    "joblib.dump(model, 'SVM.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
