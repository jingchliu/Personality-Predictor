{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/Jo/anaconda3/envs/PythonData/lib/python3.6/site-packages (0.14.0)\r\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>description</th>\n",
       "      <th>i_e</th>\n",
       "      <th>n_s</th>\n",
       "      <th>f_t</th>\n",
       "      <th>j_p</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>words_per_comment</th>\n",
       "      <th>squared_total_words</th>\n",
       "      <th>...</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>verbs</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>determiners</th>\n",
       "      <th>determiner_count</th>\n",
       "      <th>interjections</th>\n",
       "      <th>interjection_count</th>\n",
       "      <th>prepositions</th>\n",
       "      <th>preposition_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>Introvert Intuition Feeling Judging</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>11.12</td>\n",
       "      <td>22.24</td>\n",
       "      <td>...</td>\n",
       "      <td>['intj', 'life-changing', 'most', 'last', 'nex...</td>\n",
       "      <td>51</td>\n",
       "      <td>['top', 'has', 'been', 'posted', 'committing',...</td>\n",
       "      <td>90</td>\n",
       "      <td>['the', 'the', 'the', 'a', 'the', 'every', 'th...</td>\n",
       "      <td>52</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['in', 'On', 'for', 'of', 'on', 'before', 'in'...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>Extrovert Intuition Thinking Perceiving</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>0.388976</td>\n",
       "      <td>23.40</td>\n",
       "      <td>46.80</td>\n",
       "      <td>...</td>\n",
       "      <td>['same', 'missionary', 'new', 'theory.Hello', ...</td>\n",
       "      <td>96</td>\n",
       "      <td>[\"'m\", 'finding', 'be', 'boring', \"'s\", 'are',...</td>\n",
       "      <td>257</td>\n",
       "      <td>['the', 'these', 'the', 'an', 'all', 'the', 't...</td>\n",
       "      <td>90</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['of', 'in', 'if', 'in', 'For', 'in', 'Than', ...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>Introvert Intuition Thinking Perceiving</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>0.620244</td>\n",
       "      <td>16.72</td>\n",
       "      <td>33.44</td>\n",
       "      <td>...</td>\n",
       "      <td>['positive', 'best', 'amazing', 'more', 'So-ca...</td>\n",
       "      <td>82</td>\n",
       "      <td>['say', 'know', \"'s\", 'being', 'be', \"'s\", 'be...</td>\n",
       "      <td>166</td>\n",
       "      <td>['that', 'an', 'a', 'any', 'All', 'the', 'that...</td>\n",
       "      <td>52</td>\n",
       "      <td>['yes', 'No', 'Oh', 'Yessss', 'Oh']</td>\n",
       "      <td>5</td>\n",
       "      <td>['that', 'If', 'than', 'in', 'in', 'at', 'for'...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>Introvert Intuition Thinking Judging</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>0.807546</td>\n",
       "      <td>21.28</td>\n",
       "      <td>42.56</td>\n",
       "      <td>...</td>\n",
       "      <td>[\"'Dear\", 'other', 'social', 'arbitrary', 'oth...</td>\n",
       "      <td>93</td>\n",
       "      <td>['enjoyed', 'gabbing', 'being', 'created', 'hu...</td>\n",
       "      <td>233</td>\n",
       "      <td>['the', 'the', 'the', 'the', 'every', 'no', 'A...</td>\n",
       "      <td>94</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['about', 'of', 'of', 'in', 'on', 'like', 'in'...</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>Extrovert Intuition Thinking Judging</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>0.861824</td>\n",
       "      <td>19.34</td>\n",
       "      <td>38.68</td>\n",
       "      <td>...</td>\n",
       "      <td>['silly', 'super-duper-long-ass', 'permanent',...</td>\n",
       "      <td>87</td>\n",
       "      <td>[\"'re\", \"'s\", 'approaching', 'is', 'is', 'goin...</td>\n",
       "      <td>229</td>\n",
       "      <td>['another', 'the', 'a', 'the', 'that', 'that',...</td>\n",
       "      <td>84</td>\n",
       "      <td>['Oh', 'Yes']</td>\n",
       "      <td>2</td>\n",
       "      <td>['That', 'with', 'on', 'on', 'about', 'If', 'f...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  \\\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...   \n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...   \n",
       "\n",
       "                               description i_e n_s f_t j_p  sentiment_score  \\\n",
       "0      Introvert Intuition Feeling Judging   I   N   F   J         0.047100   \n",
       "1  Extrovert Intuition Thinking Perceiving   E   N   T   P         0.388976   \n",
       "2  Introvert Intuition Thinking Perceiving   I   N   T   P         0.620244   \n",
       "3     Introvert Intuition Thinking Judging   I   N   T   J         0.807546   \n",
       "4     Extrovert Intuition Thinking Judging   E   N   T   J         0.861824   \n",
       "\n",
       "   words_per_comment  squared_total_words  ...  \\\n",
       "0              11.12                22.24  ...   \n",
       "1              23.40                46.80  ...   \n",
       "2              16.72                33.44  ...   \n",
       "3              21.28                42.56  ...   \n",
       "4              19.34                38.68  ...   \n",
       "\n",
       "                                          adjectives  adjective_count  \\\n",
       "0  ['intj', 'life-changing', 'most', 'last', 'nex...               51   \n",
       "1  ['same', 'missionary', 'new', 'theory.Hello', ...               96   \n",
       "2  ['positive', 'best', 'amazing', 'more', 'So-ca...               82   \n",
       "3  [\"'Dear\", 'other', 'social', 'arbitrary', 'oth...               93   \n",
       "4  ['silly', 'super-duper-long-ass', 'permanent',...               87   \n",
       "\n",
       "                                               verbs verb_count  \\\n",
       "0  ['top', 'has', 'been', 'posted', 'committing',...         90   \n",
       "1  [\"'m\", 'finding', 'be', 'boring', \"'s\", 'are',...        257   \n",
       "2  ['say', 'know', \"'s\", 'being', 'be', \"'s\", 'be...        166   \n",
       "3  ['enjoyed', 'gabbing', 'being', 'created', 'hu...        233   \n",
       "4  [\"'re\", \"'s\", 'approaching', 'is', 'is', 'goin...        229   \n",
       "\n",
       "                                         determiners determiner_count  \\\n",
       "0  ['the', 'the', 'the', 'a', 'the', 'every', 'th...               52   \n",
       "1  ['the', 'these', 'the', 'an', 'all', 'the', 't...               90   \n",
       "2  ['that', 'an', 'a', 'any', 'All', 'the', 'that...               52   \n",
       "3  ['the', 'the', 'the', 'the', 'every', 'no', 'A...               94   \n",
       "4  ['another', 'the', 'a', 'the', 'that', 'that',...               84   \n",
       "\n",
       "                         interjections interjection_count  \\\n",
       "0                                   []                  0   \n",
       "1                                   []                  0   \n",
       "2  ['yes', 'No', 'Oh', 'Yessss', 'Oh']                  5   \n",
       "3                                   []                  0   \n",
       "4                        ['Oh', 'Yes']                  2   \n",
       "\n",
       "                                        prepositions preposition_count  \n",
       "0  ['in', 'On', 'for', 'of', 'on', 'before', 'in'...                78  \n",
       "1  ['of', 'in', 'if', 'in', 'For', 'in', 'Than', ...               136  \n",
       "2  ['that', 'If', 'than', 'in', 'in', 'at', 'for'...                91  \n",
       "3  ['about', 'of', 'of', 'in', 'on', 'like', 'in'...               124  \n",
       "4  ['That', 'with', 'on', 'on', 'about', 'If', 'f...                84  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df = pd.read_csv(\"Resources/mbti_final.csv\")\n",
    "mbti_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'posts', 'description', 'i_e', 'n_s', 'f_t', 'j_p',\n",
       "       'sentiment_score', 'words_per_comment', 'squared_total_words',\n",
       "       'word_count_variance_per_comment', 'interrobangs_per_comment',\n",
       "       'Tagged Posts PosTag', 'nouns', 'noun_count', 'adjectives',\n",
       "       'adjective_count', 'verbs', 'verb_count', 'determiners',\n",
       "       'determiner_count', 'interjections', 'interjection_count',\n",
       "       'prepositions', 'preposition_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features = mbti_df[['sentiment_score', 'words_per_comment', 'squared_total_words',\n",
    "       'word_count_variance_per_comment', 'interrobangs_per_comment','noun_count', \n",
    "       'adjective_count', 'verb_count', \n",
    "       'determiner_count', 'interjection_count','preposition_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = mbti_df[\"type\"]\n",
    "target_names = [\"INFJ\",\"INFP\",\"INTJ\",'INTP',\"ISFJ\",\"ISFP\",\"ISTJ\",'ISTP',\"ENFJ\",\"ENFP\",\"ENTJ\",'ENTP',\"ESFJ\",\"ESFP\",\"ESTJ\",'ESTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>words_per_comment</th>\n",
       "      <th>squared_total_words</th>\n",
       "      <th>word_count_variance_per_comment</th>\n",
       "      <th>interrobangs_per_comment</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>determiner_count</th>\n",
       "      <th>interjection_count</th>\n",
       "      <th>preposition_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>571.406128</td>\n",
       "      <td>28.22</td>\n",
       "      <td>56.44</td>\n",
       "      <td>127.840000</td>\n",
       "      <td>1.14</td>\n",
       "      <td>310</td>\n",
       "      <td>123</td>\n",
       "      <td>305</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>534.330686</td>\n",
       "      <td>20.92</td>\n",
       "      <td>41.84</td>\n",
       "      <td>186.370000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>296</td>\n",
       "      <td>80</td>\n",
       "      <td>202</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>891.721612</td>\n",
       "      <td>25.90</td>\n",
       "      <td>51.80</td>\n",
       "      <td>113.785600</td>\n",
       "      <td>0.74</td>\n",
       "      <td>213</td>\n",
       "      <td>113</td>\n",
       "      <td>318</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>1363.673841</td>\n",
       "      <td>30.04</td>\n",
       "      <td>60.08</td>\n",
       "      <td>110.109954</td>\n",
       "      <td>0.16</td>\n",
       "      <td>291</td>\n",
       "      <td>92</td>\n",
       "      <td>348</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>717.557672</td>\n",
       "      <td>28.98</td>\n",
       "      <td>57.96</td>\n",
       "      <td>131.278400</td>\n",
       "      <td>0.60</td>\n",
       "      <td>267</td>\n",
       "      <td>100</td>\n",
       "      <td>334</td>\n",
       "      <td>126</td>\n",
       "      <td>7</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment_score  words_per_comment  squared_total_words  \\\n",
       "2706       571.406128              28.22                56.44   \n",
       "2521       534.330686              20.92                41.84   \n",
       "4192       891.721612              25.90                51.80   \n",
       "6296      1363.673841              30.04                60.08   \n",
       "3399       717.557672              28.98                57.96   \n",
       "\n",
       "      word_count_variance_per_comment  interrobangs_per_comment  noun_count  \\\n",
       "2706                       127.840000                      1.14         310   \n",
       "2521                       186.370000                      0.24         296   \n",
       "4192                       113.785600                      0.74         213   \n",
       "6296                       110.109954                      0.16         291   \n",
       "3399                       131.278400                      0.60         267   \n",
       "\n",
       "      adjective_count  verb_count  determiner_count  interjection_count  \\\n",
       "2706              123         305                99                   0   \n",
       "2521               80         202                81                   0   \n",
       "4192              113         318                68                   1   \n",
       "6296               92         348               107                   3   \n",
       "3399              100         334               126                   7   \n",
       "\n",
       "      preposition_count  \n",
       "2706                124  \n",
       "2521                115  \n",
       "4192                132  \n",
       "6296                167  \n",
       "3399                152  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_categorical.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 2.3386 - accuracy: 0.1990\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2.2467 - accuracy: 0.2272\n",
      "Epoch 3/100\n",
      " - 0s - loss: 2.2293 - accuracy: 0.2264\n",
      "Epoch 4/100\n",
      " - 0s - loss: 2.2154 - accuracy: 0.2344\n",
      "Epoch 5/100\n",
      " - 0s - loss: 2.2086 - accuracy: 0.2355\n",
      "Epoch 6/100\n",
      " - 0s - loss: 2.2001 - accuracy: 0.2384\n",
      "Epoch 7/100\n",
      " - 0s - loss: 2.1948 - accuracy: 0.2369\n",
      "Epoch 8/100\n",
      " - 0s - loss: 2.1871 - accuracy: 0.2409\n",
      "Epoch 9/100\n",
      " - 1s - loss: 2.1819 - accuracy: 0.2458\n",
      "Epoch 10/100\n",
      " - 1s - loss: 2.1793 - accuracy: 0.2456\n",
      "Epoch 11/100\n",
      " - 1s - loss: 2.1720 - accuracy: 0.2472\n",
      "Epoch 12/100\n",
      " - 1s - loss: 2.1695 - accuracy: 0.2464\n",
      "Epoch 13/100\n",
      " - 1s - loss: 2.1622 - accuracy: 0.2461\n",
      "Epoch 14/100\n",
      " - 1s - loss: 2.1579 - accuracy: 0.2479\n",
      "Epoch 15/100\n",
      " - 1s - loss: 2.1545 - accuracy: 0.2544\n",
      "Epoch 16/100\n",
      " - 1s - loss: 2.1477 - accuracy: 0.2551\n",
      "Epoch 17/100\n",
      " - 1s - loss: 2.1409 - accuracy: 0.2596\n",
      "Epoch 18/100\n",
      " - 1s - loss: 2.1353 - accuracy: 0.2608\n",
      "Epoch 19/100\n",
      " - 1s - loss: 2.1301 - accuracy: 0.2639\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2.1282 - accuracy: 0.2615\n",
      "Epoch 21/100\n",
      " - 1s - loss: 2.1215 - accuracy: 0.2641\n",
      "Epoch 22/100\n",
      " - 1s - loss: 2.1149 - accuracy: 0.2690\n",
      "Epoch 23/100\n",
      " - 1s - loss: 2.1119 - accuracy: 0.2721\n",
      "Epoch 24/100\n",
      " - 1s - loss: 2.1042 - accuracy: 0.2694\n",
      "Epoch 25/100\n",
      " - 1s - loss: 2.0987 - accuracy: 0.2747\n",
      "Epoch 26/100\n",
      " - 1s - loss: 2.0941 - accuracy: 0.2736\n",
      "Epoch 27/100\n",
      " - 1s - loss: 2.0873 - accuracy: 0.2745\n",
      "Epoch 28/100\n",
      " - 1s - loss: 2.0814 - accuracy: 0.2802\n",
      "Epoch 29/100\n",
      " - 1s - loss: 2.0739 - accuracy: 0.2784\n",
      "Epoch 30/100\n",
      " - 1s - loss: 2.0691 - accuracy: 0.2867\n",
      "Epoch 31/100\n",
      " - 1s - loss: 2.0657 - accuracy: 0.2851\n",
      "Epoch 32/100\n",
      " - 1s - loss: 2.0593 - accuracy: 0.2922\n",
      "Epoch 33/100\n",
      " - 1s - loss: 2.0515 - accuracy: 0.2877\n",
      "Epoch 34/100\n",
      " - 1s - loss: 2.0466 - accuracy: 0.2934\n",
      "Epoch 35/100\n",
      " - 1s - loss: 2.0409 - accuracy: 0.2879\n",
      "Epoch 36/100\n",
      " - 1s - loss: 2.0353 - accuracy: 0.2945\n",
      "Epoch 37/100\n",
      " - 1s - loss: 2.0314 - accuracy: 0.2936\n",
      "Epoch 38/100\n",
      " - 1s - loss: 2.0225 - accuracy: 0.3016\n",
      "Epoch 39/100\n",
      " - 1s - loss: 2.0173 - accuracy: 0.3023\n",
      "Epoch 40/100\n",
      " - 1s - loss: 2.0128 - accuracy: 0.3069\n",
      "Epoch 41/100\n",
      " - 1s - loss: 2.0059 - accuracy: 0.3046\n",
      "Epoch 42/100\n",
      " - 1s - loss: 2.0018 - accuracy: 0.3063\n",
      "Epoch 43/100\n",
      " - 1s - loss: 1.9933 - accuracy: 0.3083\n",
      "Epoch 44/100\n",
      " - 1s - loss: 1.9882 - accuracy: 0.3094\n",
      "Epoch 45/100\n",
      " - 1s - loss: 1.9855 - accuracy: 0.3096\n",
      "Epoch 46/100\n",
      " - 1s - loss: 1.9761 - accuracy: 0.3159\n",
      "Epoch 47/100\n",
      " - 1s - loss: 1.9707 - accuracy: 0.3240\n",
      "Epoch 48/100\n",
      " - 1s - loss: 1.9641 - accuracy: 0.3200\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.9595 - accuracy: 0.3196\n",
      "Epoch 50/100\n",
      " - 1s - loss: 1.9587 - accuracy: 0.3202\n",
      "Epoch 51/100\n",
      " - 1s - loss: 1.9480 - accuracy: 0.3232\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.9435 - accuracy: 0.3202\n",
      "Epoch 53/100\n",
      " - 1s - loss: 1.9408 - accuracy: 0.3285\n",
      "Epoch 54/100\n",
      " - 1s - loss: 1.9360 - accuracy: 0.3289\n",
      "Epoch 55/100\n",
      " - 1s - loss: 1.9264 - accuracy: 0.3306\n",
      "Epoch 56/100\n",
      " - 1s - loss: 1.9210 - accuracy: 0.3311\n",
      "Epoch 57/100\n",
      " - 1s - loss: 1.9193 - accuracy: 0.3314\n",
      "Epoch 58/100\n",
      " - 1s - loss: 1.9128 - accuracy: 0.3380\n",
      "Epoch 59/100\n",
      " - 1s - loss: 1.9108 - accuracy: 0.3363\n",
      "Epoch 60/100\n",
      " - 1s - loss: 1.9031 - accuracy: 0.3395\n",
      "Epoch 61/100\n",
      " - 1s - loss: 1.8959 - accuracy: 0.3421\n",
      "Epoch 62/100\n",
      " - 1s - loss: 1.8950 - accuracy: 0.3411\n",
      "Epoch 63/100\n",
      " - 1s - loss: 1.8874 - accuracy: 0.3423\n",
      "Epoch 64/100\n",
      " - 1s - loss: 1.8825 - accuracy: 0.3383\n",
      "Epoch 65/100\n",
      " - 1s - loss: 1.8756 - accuracy: 0.3521\n",
      "Epoch 66/100\n",
      " - 1s - loss: 1.8747 - accuracy: 0.3523\n",
      "Epoch 67/100\n",
      " - 1s - loss: 1.8671 - accuracy: 0.3494\n",
      "Epoch 68/100\n",
      " - 1s - loss: 1.8622 - accuracy: 0.3566\n",
      "Epoch 69/100\n",
      " - 1s - loss: 1.8575 - accuracy: 0.3503\n",
      "Epoch 70/100\n",
      " - 1s - loss: 1.8511 - accuracy: 0.3560\n",
      "Epoch 71/100\n",
      " - 1s - loss: 1.8460 - accuracy: 0.3635\n",
      "Epoch 72/100\n",
      " - 1s - loss: 1.8406 - accuracy: 0.3571\n",
      "Epoch 73/100\n",
      " - 1s - loss: 1.8373 - accuracy: 0.3561\n",
      "Epoch 74/100\n",
      " - 1s - loss: 1.8325 - accuracy: 0.3581\n",
      "Epoch 75/100\n",
      " - 1s - loss: 1.8247 - accuracy: 0.3669\n",
      "Epoch 76/100\n",
      " - 1s - loss: 1.8251 - accuracy: 0.3641\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.8175 - accuracy: 0.3684\n",
      "Epoch 78/100\n",
      " - 1s - loss: 1.8140 - accuracy: 0.3669\n",
      "Epoch 79/100\n",
      " - 1s - loss: 1.8076 - accuracy: 0.3686\n",
      "Epoch 80/100\n",
      " - 1s - loss: 1.8050 - accuracy: 0.3667\n",
      "Epoch 81/100\n",
      " - 1s - loss: 1.7988 - accuracy: 0.3735\n",
      "Epoch 82/100\n",
      " - 1s - loss: 1.7929 - accuracy: 0.3741\n",
      "Epoch 83/100\n",
      " - 1s - loss: 1.7882 - accuracy: 0.3750\n",
      "Epoch 84/100\n",
      " - 1s - loss: 1.7887 - accuracy: 0.3712\n",
      "Epoch 85/100\n",
      " - 1s - loss: 1.7767 - accuracy: 0.3792\n",
      "Epoch 86/100\n",
      " - 1s - loss: 1.7797 - accuracy: 0.3727\n",
      "Epoch 87/100\n",
      " - 1s - loss: 1.7676 - accuracy: 0.3810\n",
      "Epoch 88/100\n",
      " - 1s - loss: 1.7698 - accuracy: 0.3798\n",
      "Epoch 89/100\n",
      " - 1s - loss: 1.7674 - accuracy: 0.3789\n",
      "Epoch 90/100\n",
      " - 1s - loss: 1.7563 - accuracy: 0.3861\n",
      "Epoch 91/100\n",
      " - 1s - loss: 1.7546 - accuracy: 0.3863\n",
      "Epoch 92/100\n",
      " - 1s - loss: 1.7480 - accuracy: 0.3875\n",
      "Epoch 93/100\n",
      " - 1s - loss: 1.7485 - accuracy: 0.3907\n",
      "Epoch 94/100\n",
      " - 1s - loss: 1.7427 - accuracy: 0.3881\n",
      "Epoch 95/100\n",
      " - 1s - loss: 1.7392 - accuracy: 0.3903\n",
      "Epoch 96/100\n",
      " - 1s - loss: 1.7328 - accuracy: 0.3890\n",
      "Epoch 97/100\n",
      " - 1s - loss: 1.7294 - accuracy: 0.3952\n",
      "Epoch 98/100\n",
      " - 1s - loss: 1.7305 - accuracy: 0.3975\n",
      "Epoch 99/100\n",
      " - 1s - loss: 1.7244 - accuracy: 0.3969\n",
      "Epoch 100/100\n",
      " - 1s - loss: 1.7189 - accuracy: 0.3939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13034fdd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=16, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train_categorical, epochs=100, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6908737343541484, Accuracy: 0.17242969572544098\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test for I vs. E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 0.5530 - accuracy: 0.7605\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.5375 - accuracy: 0.7638\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.5345 - accuracy: 0.7659\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5326 - accuracy: 0.7667\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.5304 - accuracy: 0.7664\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.5283 - accuracy: 0.7664\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5265 - accuracy: 0.7674\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5250 - accuracy: 0.7693\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.5247 - accuracy: 0.7673\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.5235 - accuracy: 0.7682\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.5199 - accuracy: 0.7681\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.5205 - accuracy: 0.7673\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.5174 - accuracy: 0.7682\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.5142 - accuracy: 0.7714\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.5150 - accuracy: 0.7684\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.5117 - accuracy: 0.7701\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.5095 - accuracy: 0.7687\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.5052 - accuracy: 0.7717\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.5037 - accuracy: 0.7728\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.5022 - accuracy: 0.7736\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.4981 - accuracy: 0.7757\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.4947 - accuracy: 0.7734\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.4931 - accuracy: 0.7773\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.4926 - accuracy: 0.7788\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.4886 - accuracy: 0.7796\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.4860 - accuracy: 0.7813\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.4810 - accuracy: 0.7837\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.4801 - accuracy: 0.7842\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.4740 - accuracy: 0.7870\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.4739 - accuracy: 0.7853\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.4698 - accuracy: 0.7894\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.4657 - accuracy: 0.7919\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.4654 - accuracy: 0.7925\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.4580 - accuracy: 0.7934\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.4592 - accuracy: 0.7931\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.4551 - accuracy: 0.7966\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.4527 - accuracy: 0.7976\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.4505 - accuracy: 0.7957\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.4437 - accuracy: 0.8003\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.4406 - accuracy: 0.8028\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.4397 - accuracy: 0.8031\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.4355 - accuracy: 0.8023\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.4341 - accuracy: 0.8077\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.4282 - accuracy: 0.8077\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.4262 - accuracy: 0.8123\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.4257 - accuracy: 0.8091\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.4197 - accuracy: 0.8140\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.4164 - accuracy: 0.8171\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.4137 - accuracy: 0.8180\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.4142 - accuracy: 0.8152\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.4074 - accuracy: 0.8192\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.4063 - accuracy: 0.8232\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.4018 - accuracy: 0.8237\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3995 - accuracy: 0.8268\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3973 - accuracy: 0.8277\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3918 - accuracy: 0.8272\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3906 - accuracy: 0.8311\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3858 - accuracy: 0.8335\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3825 - accuracy: 0.8346\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3796 - accuracy: 0.8368\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3746 - accuracy: 0.8389\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3762 - accuracy: 0.8380\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3681 - accuracy: 0.8406\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3670 - accuracy: 0.8429\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3648 - accuracy: 0.8431\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3611 - accuracy: 0.8417\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3592 - accuracy: 0.8440\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3549 - accuracy: 0.8483\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3541 - accuracy: 0.8461\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3503 - accuracy: 0.8471\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3474 - accuracy: 0.8500\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3424 - accuracy: 0.8517\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3386 - accuracy: 0.8557\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3341 - accuracy: 0.8586\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3327 - accuracy: 0.8561\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3298 - accuracy: 0.8589\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3345 - accuracy: 0.8540\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3232 - accuracy: 0.8601\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3265 - accuracy: 0.8583\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3174 - accuracy: 0.8713\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3168 - accuracy: 0.8644\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3156 - accuracy: 0.8657\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3170 - accuracy: 0.8654\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3047 - accuracy: 0.8740\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3021 - accuracy: 0.8747\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3021 - accuracy: 0.8772\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2973 - accuracy: 0.8786\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2991 - accuracy: 0.8701\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2932 - accuracy: 0.8793\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2933 - accuracy: 0.8826\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2851 - accuracy: 0.8838\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2845 - accuracy: 0.8826\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2766 - accuracy: 0.8906\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2781 - accuracy: 0.8861\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2738 - accuracy: 0.8879\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2732 - accuracy: 0.8883\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2761 - accuracy: 0.8849\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2655 - accuracy: 0.8887\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2707 - accuracy: 0.8896\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2655 - accuracy: 0.8899\n",
      "I vs. E - Loss: 0.8557536789710316, Accuracy: 0.7044721245765686\n"
     ]
    }
   ],
   "source": [
    "target = mbti_df[\"i_e\"]\n",
    "target_names = [\"Introvert\",\"Extrovert\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train_categorical, epochs=100, shuffle=True, verbose=2)\n",
    "\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"I vs. E - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test for N vs. S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 0.4296 - accuracy: 0.8515\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4027 - accuracy: 0.8632\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3987 - accuracy: 0.8632\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3956 - accuracy: 0.8629\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3932 - accuracy: 0.8630\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3911 - accuracy: 0.8635\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3916 - accuracy: 0.8630\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3885 - accuracy: 0.8634\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3889 - accuracy: 0.8624\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3872 - accuracy: 0.8630\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3854 - accuracy: 0.8634\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3844 - accuracy: 0.8637\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3830 - accuracy: 0.8632\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3818 - accuracy: 0.8635\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3808 - accuracy: 0.8640\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3782 - accuracy: 0.8630\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3775 - accuracy: 0.8637\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3724 - accuracy: 0.8638\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3738 - accuracy: 0.8641\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3718 - accuracy: 0.8641\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3676 - accuracy: 0.8644\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3662 - accuracy: 0.8641\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3646 - accuracy: 0.8655\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3644 - accuracy: 0.8649\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3639 - accuracy: 0.8657\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3574 - accuracy: 0.8657\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3569 - accuracy: 0.8674\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3563 - accuracy: 0.8664\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3526 - accuracy: 0.8678\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3503 - accuracy: 0.8666\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3494 - accuracy: 0.8678\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3457 - accuracy: 0.8690\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3447 - accuracy: 0.8683\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3413 - accuracy: 0.8686\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3389 - accuracy: 0.8706\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3380 - accuracy: 0.8713\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3334 - accuracy: 0.8712\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3323 - accuracy: 0.8721\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3303 - accuracy: 0.8707\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3249 - accuracy: 0.8735\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3240 - accuracy: 0.8749\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3206 - accuracy: 0.8746\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3228 - accuracy: 0.8746\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3172 - accuracy: 0.8755\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3157 - accuracy: 0.8753\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3127 - accuracy: 0.8773\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3090 - accuracy: 0.8778\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3090 - accuracy: 0.8752\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3049 - accuracy: 0.8770\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3019 - accuracy: 0.8781\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.2995 - accuracy: 0.8789\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.2992 - accuracy: 0.8792\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.2965 - accuracy: 0.8815\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.2916 - accuracy: 0.8824\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.2899 - accuracy: 0.8850\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.2895 - accuracy: 0.8846\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.2840 - accuracy: 0.8858\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.2812 - accuracy: 0.8856\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.2822 - accuracy: 0.8847\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.2792 - accuracy: 0.8849\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.2721 - accuracy: 0.8898\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.2715 - accuracy: 0.8903\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.2679 - accuracy: 0.8943\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.2666 - accuracy: 0.8912\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.2641 - accuracy: 0.8938\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.2646 - accuracy: 0.8953\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2573 - accuracy: 0.8943\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2566 - accuracy: 0.8961\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2534 - accuracy: 0.8961\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2509 - accuracy: 0.8989\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2523 - accuracy: 0.8995\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2424 - accuracy: 0.9035\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2483 - accuracy: 0.8996\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2428 - accuracy: 0.9039\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2388 - accuracy: 0.9024\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2342 - accuracy: 0.9055\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2324 - accuracy: 0.9085\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2338 - accuracy: 0.9067\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2319 - accuracy: 0.9095\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2257 - accuracy: 0.9101\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2232 - accuracy: 0.9130\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2202 - accuracy: 0.9092\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2195 - accuracy: 0.9116\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2139 - accuracy: 0.9155\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2204 - accuracy: 0.9150\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2114 - accuracy: 0.9165\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2139 - accuracy: 0.9161\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2076 - accuracy: 0.9168\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2074 - accuracy: 0.9192\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2064 - accuracy: 0.9201\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.1966 - accuracy: 0.9238\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.1974 - accuracy: 0.9244\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.1954 - accuracy: 0.9233\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.1952 - accuracy: 0.9242\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.1983 - accuracy: 0.9238\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.1922 - accuracy: 0.9282\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.1879 - accuracy: 0.9275\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.1868 - accuracy: 0.9284\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.1838 - accuracy: 0.9282\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.1874 - accuracy: 0.9250\n",
      "N vs. S - Loss: 0.7295967812579917, Accuracy: 0.7786998748779297\n"
     ]
    }
   ],
   "source": [
    "target = mbti_df[\"n_s\"]\n",
    "target_names = [\"Intuition\",\"Sensing\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train_categorical, epochs=100, shuffle=True, verbose=2)\n",
    "\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"N vs. S - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test for F vs. J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 0.6678 - accuracy: 0.5870\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6561 - accuracy: 0.6059\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6516 - accuracy: 0.6125\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.6494 - accuracy: 0.6153\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.6458 - accuracy: 0.6190\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6454 - accuracy: 0.6176\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.6415 - accuracy: 0.6227\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.6405 - accuracy: 0.6283\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.6377 - accuracy: 0.6293\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.6368 - accuracy: 0.6279\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.6337 - accuracy: 0.6334\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.6340 - accuracy: 0.6323\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.6292 - accuracy: 0.6377\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.6308 - accuracy: 0.6388\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.6254 - accuracy: 0.6429\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.6237 - accuracy: 0.6474\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.6220 - accuracy: 0.6491\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.6200 - accuracy: 0.6491\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.6176 - accuracy: 0.6531\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.6150 - accuracy: 0.6559\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.6113 - accuracy: 0.6566\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.6091 - accuracy: 0.6629\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.6072 - accuracy: 0.6649\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.6042 - accuracy: 0.6662\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.6017 - accuracy: 0.6692\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.5985 - accuracy: 0.6712\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.5964 - accuracy: 0.6731\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.5908 - accuracy: 0.6738\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.5884 - accuracy: 0.6785\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.5844 - accuracy: 0.6855\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.5802 - accuracy: 0.6817\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.5799 - accuracy: 0.6864\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.5784 - accuracy: 0.6894\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.5720 - accuracy: 0.6903\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.5706 - accuracy: 0.6941\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.5655 - accuracy: 0.6970\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.5652 - accuracy: 0.7006\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.5601 - accuracy: 0.7044\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.5563 - accuracy: 0.7112\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.5512 - accuracy: 0.7107\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.5479 - accuracy: 0.7130\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.5476 - accuracy: 0.7201\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.5442 - accuracy: 0.7138\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.5393 - accuracy: 0.7221\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.5356 - accuracy: 0.7250\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.5298 - accuracy: 0.7253\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.5270 - accuracy: 0.7281\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.5282 - accuracy: 0.7336\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.5235 - accuracy: 0.7342\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.5208 - accuracy: 0.7350\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.5154 - accuracy: 0.7376\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.5131 - accuracy: 0.7405\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.5095 - accuracy: 0.7424\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.5039 - accuracy: 0.7485\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.5008 - accuracy: 0.7464\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.4979 - accuracy: 0.7539\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.4940 - accuracy: 0.7518\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.4895 - accuracy: 0.7607\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.4857 - accuracy: 0.7624\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.4832 - accuracy: 0.7610\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.4796 - accuracy: 0.7634\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.4792 - accuracy: 0.7633\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.4770 - accuracy: 0.7659\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.4690 - accuracy: 0.7698\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.4669 - accuracy: 0.7754\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.4627 - accuracy: 0.7764\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.4577 - accuracy: 0.7797\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.4613 - accuracy: 0.7807\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.4535 - accuracy: 0.7845\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.4484 - accuracy: 0.7891\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.4508 - accuracy: 0.7871\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.4423 - accuracy: 0.7933\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.4385 - accuracy: 0.7983\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.4371 - accuracy: 0.7959\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.4354 - accuracy: 0.7996\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.4275 - accuracy: 0.7980\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.4299 - accuracy: 0.7971\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.4238 - accuracy: 0.8020\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.4216 - accuracy: 0.8083\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.4165 - accuracy: 0.8086\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.4152 - accuracy: 0.8065\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.4133 - accuracy: 0.8071\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.4079 - accuracy: 0.8179\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.4057 - accuracy: 0.8168\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.4001 - accuracy: 0.8168\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.4007 - accuracy: 0.8168\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3966 - accuracy: 0.8205\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3885 - accuracy: 0.8242\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3872 - accuracy: 0.8263\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3879 - accuracy: 0.8254\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3905 - accuracy: 0.8234\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3786 - accuracy: 0.8280\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3741 - accuracy: 0.8349\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3708 - accuracy: 0.8354\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3717 - accuracy: 0.8372\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3684 - accuracy: 0.8406\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3676 - accuracy: 0.8386\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3609 - accuracy: 0.8434\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3542 - accuracy: 0.8409\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3586 - accuracy: 0.8425\n",
      "F vs. J - Loss: 1.0430093262810045, Accuracy: 0.55924391746521\n"
     ]
    }
   ],
   "source": [
    "target = mbti_df[\"f_t\"]\n",
    "target_names = [\"Feeling\",\"Thinking\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train_categorical, epochs=100, shuffle=True, verbose=2)\n",
    "\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"F vs. J - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test for J vs. P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 0.6784 - accuracy: 0.5876\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.6702 - accuracy: 0.5974\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6691 - accuracy: 0.5979\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.6673 - accuracy: 0.6010\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.6655 - accuracy: 0.6042\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6631 - accuracy: 0.6007\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.6643 - accuracy: 0.6039\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.6620 - accuracy: 0.6033\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.6614 - accuracy: 0.6034\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.6586 - accuracy: 0.6082\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.6579 - accuracy: 0.6097\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.6561 - accuracy: 0.6102\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.6539 - accuracy: 0.6153\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.6536 - accuracy: 0.6142\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.6498 - accuracy: 0.6239\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.6491 - accuracy: 0.6222\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.6453 - accuracy: 0.6259\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.6436 - accuracy: 0.6267\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.6429 - accuracy: 0.6299\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.6391 - accuracy: 0.6323\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.6376 - accuracy: 0.6366\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.6309 - accuracy: 0.6425\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.6306 - accuracy: 0.6393\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.6257 - accuracy: 0.6491\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.6254 - accuracy: 0.6488\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.6208 - accuracy: 0.6557\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.6161 - accuracy: 0.6603\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.6125 - accuracy: 0.6622\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.6085 - accuracy: 0.6629\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.6045 - accuracy: 0.6698\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.6013 - accuracy: 0.6794\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.6007 - accuracy: 0.6752\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.5961 - accuracy: 0.6768\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.5901 - accuracy: 0.6861\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.5869 - accuracy: 0.6863\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.5842 - accuracy: 0.6834\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.5780 - accuracy: 0.6883\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.5749 - accuracy: 0.6980\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.5704 - accuracy: 0.7017\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.5708 - accuracy: 0.7034\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.5636 - accuracy: 0.7078\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.5604 - accuracy: 0.7086\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.5578 - accuracy: 0.7093\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.5544 - accuracy: 0.7155\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.5453 - accuracy: 0.7215\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.5443 - accuracy: 0.7183\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.5455 - accuracy: 0.7180\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.5385 - accuracy: 0.7207\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.5367 - accuracy: 0.7296\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.5325 - accuracy: 0.7292\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.5280 - accuracy: 0.7333\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.5242 - accuracy: 0.7339\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.5214 - accuracy: 0.7355\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.5123 - accuracy: 0.7476\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.5124 - accuracy: 0.7438\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.5086 - accuracy: 0.7461\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.5034 - accuracy: 0.7470\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.5012 - accuracy: 0.7468\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.4966 - accuracy: 0.7548\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.4910 - accuracy: 0.7608\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.4881 - accuracy: 0.7595\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.4852 - accuracy: 0.7653\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.4832 - accuracy: 0.7601\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.4772 - accuracy: 0.7682\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.4713 - accuracy: 0.7731\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.4674 - accuracy: 0.7728\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.4720 - accuracy: 0.7694\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.4627 - accuracy: 0.7781\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.4606 - accuracy: 0.7819\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.4519 - accuracy: 0.7864\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.4515 - accuracy: 0.7916\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.4467 - accuracy: 0.7897\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.4439 - accuracy: 0.7917\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.4402 - accuracy: 0.7951\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.4349 - accuracy: 0.7986\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.4366 - accuracy: 0.7947\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.4313 - accuracy: 0.7962\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.4286 - accuracy: 0.8017\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.4269 - accuracy: 0.8003\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.4190 - accuracy: 0.8057\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.4111 - accuracy: 0.8119\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.4114 - accuracy: 0.8132\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.4064 - accuracy: 0.8159\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.4079 - accuracy: 0.8163\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.4030 - accuracy: 0.8149\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3972 - accuracy: 0.8248\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3980 - accuracy: 0.8185\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3989 - accuracy: 0.8199\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3868 - accuracy: 0.8265\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3879 - accuracy: 0.8243\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3864 - accuracy: 0.8282\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3774 - accuracy: 0.8288\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3730 - accuracy: 0.8375\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3741 - accuracy: 0.8337\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3711 - accuracy: 0.8354\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3717 - accuracy: 0.8377\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3632 - accuracy: 0.8434\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3590 - accuracy: 0.8471\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3613 - accuracy: 0.8403\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3560 - accuracy: 0.8463\n",
      "J vs. P - Loss: 1.1295677221772198, Accuracy: 0.5444905757904053\n"
     ]
    }
   ],
   "source": [
    "target = mbti_df[\"j_p\"]\n",
    "target_names = [\"Judging\",\"Perceiving\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train_categorical, epochs=100, shuffle=True, verbose=2)\n",
    "\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"J vs. P - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Batch Size and Number of Epochs\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "def create_model(init_mode='uniform'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=17))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=3, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "model_CV = KerasClassifier(build_fn=create_model, epochs=epochs, \n",
    "                           batch_size=batch_size, verbose=2)\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(model_CV, param_grid, n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 1s - loss: 0.7456 - accuracy: 0.6468\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.6633 - accuracy: 0.7019\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.6343 - accuracy: 0.7130\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.6172 - accuracy: 0.7187\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.6046 - accuracy: 0.7271\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.5880 - accuracy: 0.7305\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.5813 - accuracy: 0.7406\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.5756 - accuracy: 0.7391\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.5654 - accuracy: 0.7471\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.5607 - accuracy: 0.7477\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.5573 - accuracy: 0.7465\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.5505 - accuracy: 0.7465\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.5412 - accuracy: 0.7475\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.5381 - accuracy: 0.7580\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.5306 - accuracy: 0.7572\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.5264 - accuracy: 0.7644\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.5259 - accuracy: 0.7656\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.5150 - accuracy: 0.7660\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.5115 - accuracy: 0.7704\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.5098 - accuracy: 0.7713\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.5075 - accuracy: 0.7671\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.4963 - accuracy: 0.7767\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.4962 - accuracy: 0.7776\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.4872 - accuracy: 0.7829\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.4831 - accuracy: 0.7847\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.4792 - accuracy: 0.7854\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.4760 - accuracy: 0.7845\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.4739 - accuracy: 0.7858\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.4679 - accuracy: 0.7912\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.4634 - accuracy: 0.7946\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.4594 - accuracy: 0.7948\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.4547 - accuracy: 0.8003\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.4483 - accuracy: 0.7969\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.4436 - accuracy: 0.8058\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.4408 - accuracy: 0.8066\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.4399 - accuracy: 0.8068\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.4328 - accuracy: 0.8119\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.4321 - accuracy: 0.8089\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.4271 - accuracy: 0.8108\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.4178 - accuracy: 0.8159\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.4188 - accuracy: 0.8173\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.4123 - accuracy: 0.8238\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.4101 - accuracy: 0.8200\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.4107 - accuracy: 0.8171\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.4068 - accuracy: 0.8238\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.3993 - accuracy: 0.8287\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.3995 - accuracy: 0.8318\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.3952 - accuracy: 0.8291\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.3872 - accuracy: 0.8323\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.3849 - accuracy: 0.8329\n",
      "Best: 0.714476 using {'batch_size': 20, 'epochs': 50}\n",
      "0.711234 (0.006782) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.692924 (0.002598) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.689300 (0.000475) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.711043 (0.005650) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.714476 (0.006841) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.694831 (0.011362) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.709708 (0.007121) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.705321 (0.000852) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.708564 (0.008803) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.713904 (0.005109) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.704749 (0.001743) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.700744 (0.002996) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.710090 (0.001502) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.707992 (0.010136) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.699027 (0.001667) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.710662 (0.003546) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.709136 (0.006456) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.708182 (0.001742) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "grid_result=grid1.fit(X_train_scaled, y_train_categorical)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 1s - loss: 0.7094 - accuracy: 0.6769\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.6565 - accuracy: 0.7038\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.6383 - accuracy: 0.7149\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.6261 - accuracy: 0.7236\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.6183 - accuracy: 0.7219\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.6102 - accuracy: 0.7280\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.6048 - accuracy: 0.7349\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.5988 - accuracy: 0.7345\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.5947 - accuracy: 0.7364\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.5904 - accuracy: 0.7393\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.5873 - accuracy: 0.7400\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.5833 - accuracy: 0.7376\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.5802 - accuracy: 0.7406\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.5776 - accuracy: 0.7402\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.5752 - accuracy: 0.7421\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.5720 - accuracy: 0.7459\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.5701 - accuracy: 0.7454\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.5686 - accuracy: 0.7461\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.5654 - accuracy: 0.7479\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.5637 - accuracy: 0.7498\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.5617 - accuracy: 0.7498\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.5601 - accuracy: 0.7524\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.5579 - accuracy: 0.7526\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.5567 - accuracy: 0.7513\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.5558 - accuracy: 0.7549\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.5541 - accuracy: 0.7540\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.5522 - accuracy: 0.7534\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.5508 - accuracy: 0.7547\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.5486 - accuracy: 0.7549\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.5483 - accuracy: 0.7582\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.5471 - accuracy: 0.7561\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.5454 - accuracy: 0.7564\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.5442 - accuracy: 0.7597\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.5429 - accuracy: 0.7545\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.5424 - accuracy: 0.7578\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.5407 - accuracy: 0.7601\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.5396 - accuracy: 0.7595\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.5386 - accuracy: 0.7593\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.5374 - accuracy: 0.7622\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.5359 - accuracy: 0.7610\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.5354 - accuracy: 0.7604\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.5337 - accuracy: 0.7618\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.5331 - accuracy: 0.7646\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.5324 - accuracy: 0.7643\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.5312 - accuracy: 0.7633\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.5303 - accuracy: 0.7629\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.5290 - accuracy: 0.7654\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.5282 - accuracy: 0.7648\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.5274 - accuracy: 0.7654\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.5262 - accuracy: 0.7677\n",
      "Best: 0.717528 using {'optimizer': 'Adagrad'}\n",
      "0.707610 (0.009840) with: {'optimizer': 'SGD'}\n",
      "0.711234 (0.009014) with: {'optimizer': 'RMSprop'}\n",
      "0.717528 (0.005603) with: {'optimizer': 'Adagrad'}\n",
      "0.698074 (0.012614) with: {'optimizer': 'Adadelta'}\n",
      "0.698074 (0.007236) with: {'optimizer': 'Adam'}\n",
      "0.711806 (0.007292) with: {'optimizer': 'Adamax'}\n",
      "0.685295 (0.008484) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# Tune the Training Optimization Algorithm\n",
    "def create_model1(optimizer='adam'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=17))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=3, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "model_CV1 = KerasClassifier(build_fn=create_model1, epochs=50, batch_size=20, verbose=2)\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid1 = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model_CV1, param_grid=param_grid1, n_jobs=-1, cv=3)\n",
    "grid_result1 = grid.fit(X_train_scaled, y_train_categorical)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result1.best_score_, grid_result1.best_params_))\n",
    "means = grid_result1.cv_results_['mean_test_score']\n",
    "stds = grid_result1.cv_results_['std_test_score']\n",
    "params = grid_result1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 1s - loss: 0.7080 - accuracy: 0.6790\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.6498 - accuracy: 0.7118\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.6316 - accuracy: 0.7173\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.6200 - accuracy: 0.7263\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.6113 - accuracy: 0.7301\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.6033 - accuracy: 0.7330\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.5977 - accuracy: 0.7358\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.5926 - accuracy: 0.7345\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.5872 - accuracy: 0.7383\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.5842 - accuracy: 0.7385\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.5804 - accuracy: 0.7461\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.5775 - accuracy: 0.7419\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.5736 - accuracy: 0.7423\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.5713 - accuracy: 0.7429\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.5690 - accuracy: 0.7482\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.5661 - accuracy: 0.7479\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.5636 - accuracy: 0.7467\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.5616 - accuracy: 0.7480\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.5602 - accuracy: 0.7492\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.5571 - accuracy: 0.7517\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.5561 - accuracy: 0.7517\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.5542 - accuracy: 0.7515\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.5526 - accuracy: 0.7530\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.5515 - accuracy: 0.7538\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.5486 - accuracy: 0.7549\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.5487 - accuracy: 0.7564\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.5464 - accuracy: 0.7561\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.5447 - accuracy: 0.7559\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.5437 - accuracy: 0.7561\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.5417 - accuracy: 0.7564\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.5416 - accuracy: 0.7557\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.5395 - accuracy: 0.7599\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.5383 - accuracy: 0.7610\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.5370 - accuracy: 0.7574\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.5358 - accuracy: 0.7614\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.5350 - accuracy: 0.7614\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.5335 - accuracy: 0.7608\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.5327 - accuracy: 0.7610\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.5317 - accuracy: 0.7629\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.5310 - accuracy: 0.7583\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.5299 - accuracy: 0.7614\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.5287 - accuracy: 0.7629\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.5280 - accuracy: 0.7622\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.5271 - accuracy: 0.7627\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.5255 - accuracy: 0.7660\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.5245 - accuracy: 0.7648\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.5239 - accuracy: 0.7641\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.5229 - accuracy: 0.7643\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.5217 - accuracy: 0.7654\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.5211 - accuracy: 0.7646\n",
      "Best: 0.722869 using {'activation': 'relu'}\n",
      "0.662026 (0.008773) with: {'activation': 'softmax'}\n",
      "0.695403 (0.007842) with: {'activation': 'softplus'}\n",
      "0.713714 (0.005013) with: {'activation': 'softsign'}\n",
      "0.722869 (0.006828) with: {'activation': 'relu'}\n",
      "0.709708 (0.007451) with: {'activation': 'tanh'}\n",
      "0.684341 (0.011298) with: {'activation': 'sigmoid'}\n",
      "0.683387 (0.013169) with: {'activation': 'hard_sigmoid'}\n",
      "0.680908 (0.011388) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Tune the Neuron Activation Function\n",
    "def create_model2(activation='relu'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation=activation, input_dim=17))\n",
    "    model.add(Dense(units=100, activation=activation))\n",
    "    model.add(Dense(units=3, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer='Adagrad',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "model_CV2 = KerasClassifier(build_fn=create_model2, epochs=50, batch_size=20, verbose=2)\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid2 = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model_CV2, param_grid=param_grid2, n_jobs=-1, cv=3)\n",
    "\n",
    "grid_result2 = grid.fit(X_train_scaled, y_train_categorical)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result2.best_score_, grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CONFIRMED       0.48      0.42      0.45       411\n",
      "FALSE POSITIVE       0.67      0.72      0.69       484\n",
      "     CANDIDATE       0.84      0.85      0.85       853\n",
      "\n",
      "     micro avg       0.71      0.71      0.71      1748\n",
      "     macro avg       0.66      0.66      0.66      1748\n",
      "  weighted avg       0.71      0.71      0.71      1748\n",
      "   samples avg       0.71      0.71      0.71      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = grid.predict(X_test_scaled)\n",
    "predictions=to_categorical(predictions)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_categorical, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neural.sav']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "filename = 'Neural.sav'\n",
    "joblib.dump(model, 'Neural.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
