{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>description</th>\n",
       "      <th>i_e</th>\n",
       "      <th>n_s</th>\n",
       "      <th>f_t</th>\n",
       "      <th>j_p</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>words_per_comment</th>\n",
       "      <th>squared_total_words</th>\n",
       "      <th>...</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>verbs</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>determiners</th>\n",
       "      <th>determiner_count</th>\n",
       "      <th>interjections</th>\n",
       "      <th>interjection_count</th>\n",
       "      <th>prepositions</th>\n",
       "      <th>preposition_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>Introvert Intuition Feeling Judging</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>11.12</td>\n",
       "      <td>22.24</td>\n",
       "      <td>...</td>\n",
       "      <td>['intj', 'life-changing', 'most', 'last', 'nex...</td>\n",
       "      <td>51</td>\n",
       "      <td>['top', 'has', 'been', 'posted', 'committing',...</td>\n",
       "      <td>90</td>\n",
       "      <td>['the', 'the', 'the', 'a', 'the', 'every', 'th...</td>\n",
       "      <td>52</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['in', 'On', 'for', 'of', 'on', 'before', 'in'...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>Extrovert Intuition Thinking Perceiving</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>0.388976</td>\n",
       "      <td>23.40</td>\n",
       "      <td>46.80</td>\n",
       "      <td>...</td>\n",
       "      <td>['same', 'missionary', 'new', 'theory.Hello', ...</td>\n",
       "      <td>96</td>\n",
       "      <td>[\"'m\", 'finding', 'be', 'boring', \"'s\", 'are',...</td>\n",
       "      <td>257</td>\n",
       "      <td>['the', 'these', 'the', 'an', 'all', 'the', 't...</td>\n",
       "      <td>90</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['of', 'in', 'if', 'in', 'For', 'in', 'Than', ...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>Introvert Intuition Thinking Perceiving</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>0.620244</td>\n",
       "      <td>16.72</td>\n",
       "      <td>33.44</td>\n",
       "      <td>...</td>\n",
       "      <td>['positive', 'best', 'amazing', 'more', 'So-ca...</td>\n",
       "      <td>82</td>\n",
       "      <td>['say', 'know', \"'s\", 'being', 'be', \"'s\", 'be...</td>\n",
       "      <td>166</td>\n",
       "      <td>['that', 'an', 'a', 'any', 'All', 'the', 'that...</td>\n",
       "      <td>52</td>\n",
       "      <td>['yes', 'No', 'Oh', 'Yessss', 'Oh']</td>\n",
       "      <td>5</td>\n",
       "      <td>['that', 'If', 'than', 'in', 'in', 'at', 'for'...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>Introvert Intuition Thinking Judging</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>0.807546</td>\n",
       "      <td>21.28</td>\n",
       "      <td>42.56</td>\n",
       "      <td>...</td>\n",
       "      <td>[\"'Dear\", 'other', 'social', 'arbitrary', 'oth...</td>\n",
       "      <td>93</td>\n",
       "      <td>['enjoyed', 'gabbing', 'being', 'created', 'hu...</td>\n",
       "      <td>233</td>\n",
       "      <td>['the', 'the', 'the', 'the', 'every', 'no', 'A...</td>\n",
       "      <td>94</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['about', 'of', 'of', 'in', 'on', 'like', 'in'...</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>Extrovert Intuition Thinking Judging</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>0.861824</td>\n",
       "      <td>19.34</td>\n",
       "      <td>38.68</td>\n",
       "      <td>...</td>\n",
       "      <td>['silly', 'super-duper-long-ass', 'permanent',...</td>\n",
       "      <td>87</td>\n",
       "      <td>[\"'re\", \"'s\", 'approaching', 'is', 'is', 'goin...</td>\n",
       "      <td>229</td>\n",
       "      <td>['another', 'the', 'a', 'the', 'that', 'that',...</td>\n",
       "      <td>84</td>\n",
       "      <td>['Oh', 'Yes']</td>\n",
       "      <td>2</td>\n",
       "      <td>['That', 'with', 'on', 'on', 'about', 'If', 'f...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  \\\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...   \n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...   \n",
       "\n",
       "                               description i_e n_s f_t j_p  sentiment_score  \\\n",
       "0      Introvert Intuition Feeling Judging   I   N   F   J         0.047100   \n",
       "1  Extrovert Intuition Thinking Perceiving   E   N   T   P         0.388976   \n",
       "2  Introvert Intuition Thinking Perceiving   I   N   T   P         0.620244   \n",
       "3     Introvert Intuition Thinking Judging   I   N   T   J         0.807546   \n",
       "4     Extrovert Intuition Thinking Judging   E   N   T   J         0.861824   \n",
       "\n",
       "   words_per_comment  squared_total_words  ...  \\\n",
       "0              11.12                22.24  ...   \n",
       "1              23.40                46.80  ...   \n",
       "2              16.72                33.44  ...   \n",
       "3              21.28                42.56  ...   \n",
       "4              19.34                38.68  ...   \n",
       "\n",
       "                                          adjectives  adjective_count  \\\n",
       "0  ['intj', 'life-changing', 'most', 'last', 'nex...               51   \n",
       "1  ['same', 'missionary', 'new', 'theory.Hello', ...               96   \n",
       "2  ['positive', 'best', 'amazing', 'more', 'So-ca...               82   \n",
       "3  [\"'Dear\", 'other', 'social', 'arbitrary', 'oth...               93   \n",
       "4  ['silly', 'super-duper-long-ass', 'permanent',...               87   \n",
       "\n",
       "                                               verbs verb_count  \\\n",
       "0  ['top', 'has', 'been', 'posted', 'committing',...         90   \n",
       "1  [\"'m\", 'finding', 'be', 'boring', \"'s\", 'are',...        257   \n",
       "2  ['say', 'know', \"'s\", 'being', 'be', \"'s\", 'be...        166   \n",
       "3  ['enjoyed', 'gabbing', 'being', 'created', 'hu...        233   \n",
       "4  [\"'re\", \"'s\", 'approaching', 'is', 'is', 'goin...        229   \n",
       "\n",
       "                                         determiners determiner_count  \\\n",
       "0  ['the', 'the', 'the', 'a', 'the', 'every', 'th...               52   \n",
       "1  ['the', 'these', 'the', 'an', 'all', 'the', 't...               90   \n",
       "2  ['that', 'an', 'a', 'any', 'All', 'the', 'that...               52   \n",
       "3  ['the', 'the', 'the', 'the', 'every', 'no', 'A...               94   \n",
       "4  ['another', 'the', 'a', 'the', 'that', 'that',...               84   \n",
       "\n",
       "                         interjections interjection_count  \\\n",
       "0                                   []                  0   \n",
       "1                                   []                  0   \n",
       "2  ['yes', 'No', 'Oh', 'Yessss', 'Oh']                  5   \n",
       "3                                   []                  0   \n",
       "4                        ['Oh', 'Yes']                  2   \n",
       "\n",
       "                                        prepositions preposition_count  \n",
       "0  ['in', 'On', 'for', 'of', 'on', 'before', 'in'...                78  \n",
       "1  ['of', 'in', 'if', 'in', 'For', 'in', 'Than', ...               136  \n",
       "2  ['that', 'If', 'than', 'in', 'in', 'at', 'for'...                91  \n",
       "3  ['about', 'of', 'of', 'in', 'on', 'like', 'in'...               124  \n",
       "4  ['That', 'with', 'on', 'on', 'about', 'If', 'f...                84  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df = pd.read_csv(\"Resources/mbti_final.csv\")\n",
    "mbti_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'posts', 'description', 'i_e', 'n_s', 'f_t', 'j_p',\n",
       "       'sentiment_score', 'words_per_comment', 'squared_total_words',\n",
       "       'word_count_variance_per_comment', 'interrobangs_per_comment',\n",
       "       'Tagged Posts PosTag', 'nouns', 'noun_count', 'adjectives',\n",
       "       'adjective_count', 'verbs', 'verb_count', 'determiners',\n",
       "       'determiner_count', 'interjections', 'interjection_count',\n",
       "       'prepositions', 'preposition_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features = mbti_df[['sentiment_score', 'words_per_comment', 'squared_total_words',\n",
    "       'word_count_variance_per_comment', 'interrobangs_per_comment','noun_count', \n",
    "       'adjective_count', 'verb_count', \n",
    "       'determiner_count', 'interjection_count','preposition_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = mbti_df[\"type\"]\n",
    "target_names = [\"INFJ\",\"INFP\",\"INTJ\",'INTP',\"ISFJ\",\"ISFP\",\"ISTJ\",'ISTP',\"ENFJ\",\"ENFP\",\"ENTJ\",'ENTP',\"ESFJ\",\"ESFP\",\"ESTJ\",'ESTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>words_per_comment</th>\n",
       "      <th>squared_total_words</th>\n",
       "      <th>word_count_variance_per_comment</th>\n",
       "      <th>interrobangs_per_comment</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>determiner_count</th>\n",
       "      <th>interjection_count</th>\n",
       "      <th>preposition_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>571.406128</td>\n",
       "      <td>28.22</td>\n",
       "      <td>56.44</td>\n",
       "      <td>127.840000</td>\n",
       "      <td>1.14</td>\n",
       "      <td>310</td>\n",
       "      <td>123</td>\n",
       "      <td>305</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>534.330686</td>\n",
       "      <td>20.92</td>\n",
       "      <td>41.84</td>\n",
       "      <td>186.370000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>296</td>\n",
       "      <td>80</td>\n",
       "      <td>202</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>891.721612</td>\n",
       "      <td>25.90</td>\n",
       "      <td>51.80</td>\n",
       "      <td>113.785600</td>\n",
       "      <td>0.74</td>\n",
       "      <td>213</td>\n",
       "      <td>113</td>\n",
       "      <td>318</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>1363.673841</td>\n",
       "      <td>30.04</td>\n",
       "      <td>60.08</td>\n",
       "      <td>110.109954</td>\n",
       "      <td>0.16</td>\n",
       "      <td>291</td>\n",
       "      <td>92</td>\n",
       "      <td>348</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>717.557672</td>\n",
       "      <td>28.98</td>\n",
       "      <td>57.96</td>\n",
       "      <td>131.278400</td>\n",
       "      <td>0.60</td>\n",
       "      <td>267</td>\n",
       "      <td>100</td>\n",
       "      <td>334</td>\n",
       "      <td>126</td>\n",
       "      <td>7</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment_score  words_per_comment  squared_total_words  \\\n",
       "2706       571.406128              28.22                56.44   \n",
       "2521       534.330686              20.92                41.84   \n",
       "4192       891.721612              25.90                51.80   \n",
       "6296      1363.673841              30.04                60.08   \n",
       "3399       717.557672              28.98                57.96   \n",
       "\n",
       "      word_count_variance_per_comment  interrobangs_per_comment  noun_count  \\\n",
       "2706                       127.840000                      1.14         310   \n",
       "2521                       186.370000                      0.24         296   \n",
       "4192                       113.785600                      0.74         213   \n",
       "6296                       110.109954                      0.16         291   \n",
       "3399                       131.278400                      0.60         267   \n",
       "\n",
       "      adjective_count  verb_count  determiner_count  interjection_count  \\\n",
       "2706              123         305                99                   0   \n",
       "2521               80         202                81                   0   \n",
       "4192              113         318                68                   1   \n",
       "6296               92         348               107                   3   \n",
       "3399              100         334               126                   7   \n",
       "\n",
       "      preposition_count  \n",
       "2706                124  \n",
       "2521                115  \n",
       "4192                132  \n",
       "6296                167  \n",
       "3399                152  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_categorical.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 2.3388 - accuracy: 0.2026\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2.2526 - accuracy: 0.2250\n",
      "Epoch 3/100\n",
      " - 0s - loss: 2.2290 - accuracy: 0.2313\n",
      "Epoch 4/100\n",
      " - 0s - loss: 2.2199 - accuracy: 0.2332\n",
      "Epoch 5/100\n",
      " - 0s - loss: 2.2078 - accuracy: 0.2398\n",
      "Epoch 6/100\n",
      " - 0s - loss: 2.2010 - accuracy: 0.2369\n",
      "Epoch 7/100\n",
      " - 0s - loss: 2.1948 - accuracy: 0.2416\n",
      "Epoch 8/100\n",
      " - 0s - loss: 2.1866 - accuracy: 0.2415\n",
      "Epoch 9/100\n",
      " - 0s - loss: 2.1820 - accuracy: 0.2510\n",
      "Epoch 10/100\n",
      " - 0s - loss: 2.1772 - accuracy: 0.2475\n",
      "Epoch 11/100\n",
      " - 0s - loss: 2.1738 - accuracy: 0.2445\n",
      "Epoch 12/100\n",
      " - 1s - loss: 2.1658 - accuracy: 0.2505\n",
      "Epoch 13/100\n",
      " - 1s - loss: 2.1580 - accuracy: 0.2571\n",
      "Epoch 14/100\n",
      " - 1s - loss: 2.1551 - accuracy: 0.2550\n",
      "Epoch 15/100\n",
      " - 1s - loss: 2.1500 - accuracy: 0.2599\n",
      "Epoch 16/100\n",
      " - 1s - loss: 2.1446 - accuracy: 0.2605\n",
      "Epoch 17/100\n",
      " - 1s - loss: 2.1379 - accuracy: 0.2610\n",
      "Epoch 18/100\n",
      " - 1s - loss: 2.1342 - accuracy: 0.2593\n",
      "Epoch 19/100\n",
      " - 1s - loss: 2.1251 - accuracy: 0.2638\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2.1208 - accuracy: 0.2691\n",
      "Epoch 21/100\n",
      " - 1s - loss: 2.1161 - accuracy: 0.2728\n",
      "Epoch 22/100\n",
      " - 1s - loss: 2.1114 - accuracy: 0.2721\n",
      "Epoch 23/100\n",
      " - 1s - loss: 2.1081 - accuracy: 0.2684\n",
      "Epoch 24/100\n",
      " - 1s - loss: 2.1004 - accuracy: 0.2748\n",
      "Epoch 25/100\n",
      " - 1s - loss: 2.0960 - accuracy: 0.2756\n",
      "Epoch 26/100\n",
      " - 1s - loss: 2.0898 - accuracy: 0.2794\n",
      "Epoch 27/100\n",
      " - 1s - loss: 2.0860 - accuracy: 0.2781\n",
      "Epoch 28/100\n",
      " - 1s - loss: 2.0797 - accuracy: 0.2785\n",
      "Epoch 29/100\n",
      " - 1s - loss: 2.0733 - accuracy: 0.2807\n",
      "Epoch 30/100\n",
      " - 1s - loss: 2.0674 - accuracy: 0.2882\n",
      "Epoch 31/100\n",
      " - 1s - loss: 2.0627 - accuracy: 0.2864\n",
      "Epoch 32/100\n",
      " - 1s - loss: 2.0572 - accuracy: 0.2859\n",
      "Epoch 33/100\n",
      " - 1s - loss: 2.0516 - accuracy: 0.2911\n",
      "Epoch 34/100\n",
      " - 1s - loss: 2.0476 - accuracy: 0.2899\n",
      "Epoch 35/100\n",
      " - 1s - loss: 2.0385 - accuracy: 0.2933\n",
      "Epoch 36/100\n",
      " - 1s - loss: 2.0361 - accuracy: 0.2880\n",
      "Epoch 37/100\n",
      " - 1s - loss: 2.0297 - accuracy: 0.2962\n",
      "Epoch 38/100\n",
      " - 1s - loss: 2.0234 - accuracy: 0.2974\n",
      "Epoch 39/100\n",
      " - 1s - loss: 2.0216 - accuracy: 0.2977\n",
      "Epoch 40/100\n",
      " - 1s - loss: 2.0111 - accuracy: 0.2997\n",
      "Epoch 41/100\n",
      " - 1s - loss: 2.0090 - accuracy: 0.3008\n",
      "Epoch 42/100\n",
      " - 1s - loss: 2.0027 - accuracy: 0.3068\n",
      "Epoch 43/100\n",
      " - 1s - loss: 1.9979 - accuracy: 0.3099\n",
      "Epoch 44/100\n",
      " - 1s - loss: 1.9921 - accuracy: 0.3080\n",
      "Epoch 45/100\n",
      " - 1s - loss: 1.9880 - accuracy: 0.3157\n",
      "Epoch 46/100\n",
      " - 1s - loss: 1.9795 - accuracy: 0.3108\n",
      "Epoch 47/100\n",
      " - 1s - loss: 1.9774 - accuracy: 0.3108\n",
      "Epoch 48/100\n",
      " - 1s - loss: 1.9734 - accuracy: 0.3119\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.9697 - accuracy: 0.3094\n",
      "Epoch 50/100\n",
      " - 1s - loss: 1.9610 - accuracy: 0.3156\n",
      "Epoch 51/100\n",
      " - 1s - loss: 1.9559 - accuracy: 0.3169\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.9524 - accuracy: 0.3203\n",
      "Epoch 53/100\n",
      " - 1s - loss: 1.9463 - accuracy: 0.3237\n",
      "Epoch 54/100\n",
      " - 1s - loss: 1.9384 - accuracy: 0.3257\n",
      "Epoch 55/100\n",
      " - 1s - loss: 1.9340 - accuracy: 0.3302\n",
      "Epoch 56/100\n",
      " - 1s - loss: 1.9306 - accuracy: 0.3263\n",
      "Epoch 57/100\n",
      " - 1s - loss: 1.9261 - accuracy: 0.3275\n",
      "Epoch 58/100\n",
      " - 1s - loss: 1.9186 - accuracy: 0.3311\n",
      "Epoch 59/100\n",
      " - 1s - loss: 1.9139 - accuracy: 0.3317\n",
      "Epoch 60/100\n",
      " - 1s - loss: 1.9103 - accuracy: 0.3325\n",
      "Epoch 61/100\n",
      " - 1s - loss: 1.9055 - accuracy: 0.3369\n",
      "Epoch 62/100\n",
      " - 1s - loss: 1.8976 - accuracy: 0.3389\n",
      "Epoch 63/100\n",
      " - 1s - loss: 1.8952 - accuracy: 0.3406\n",
      "Epoch 64/100\n",
      " - 1s - loss: 1.8866 - accuracy: 0.3421\n",
      "Epoch 65/100\n",
      " - 1s - loss: 1.8863 - accuracy: 0.3464\n",
      "Epoch 66/100\n",
      " - 1s - loss: 1.8806 - accuracy: 0.3401\n",
      "Epoch 67/100\n",
      " - 1s - loss: 1.8764 - accuracy: 0.3428\n",
      "Epoch 68/100\n",
      " - 1s - loss: 1.8666 - accuracy: 0.3480\n",
      "Epoch 69/100\n",
      " - 1s - loss: 1.8651 - accuracy: 0.3461\n",
      "Epoch 70/100\n",
      " - 1s - loss: 1.8593 - accuracy: 0.3520\n",
      "Epoch 71/100\n",
      " - 1s - loss: 1.8556 - accuracy: 0.3504\n",
      "Epoch 72/100\n",
      " - 1s - loss: 1.8520 - accuracy: 0.3509\n",
      "Epoch 73/100\n",
      " - 1s - loss: 1.8469 - accuracy: 0.3574\n",
      "Epoch 74/100\n",
      " - 1s - loss: 1.8422 - accuracy: 0.3643\n",
      "Epoch 75/100\n",
      " - 1s - loss: 1.8391 - accuracy: 0.3632\n",
      "Epoch 76/100\n",
      " - 1s - loss: 1.8323 - accuracy: 0.3620\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.8282 - accuracy: 0.3591\n",
      "Epoch 78/100\n",
      " - 1s - loss: 1.8205 - accuracy: 0.3611\n",
      "Epoch 79/100\n",
      " - 1s - loss: 1.8169 - accuracy: 0.3630\n",
      "Epoch 80/100\n",
      " - 1s - loss: 1.8116 - accuracy: 0.3661\n",
      "Epoch 81/100\n",
      " - 1s - loss: 1.8078 - accuracy: 0.3724\n",
      "Epoch 82/100\n",
      " - 1s - loss: 1.8027 - accuracy: 0.3681\n",
      "Epoch 83/100\n",
      " - 1s - loss: 1.8002 - accuracy: 0.3746\n",
      "Epoch 84/100\n",
      " - 1s - loss: 1.7931 - accuracy: 0.3789\n",
      "Epoch 85/100\n",
      " - 1s - loss: 1.7922 - accuracy: 0.3710\n",
      "Epoch 86/100\n",
      " - 1s - loss: 1.7884 - accuracy: 0.3752\n",
      "Epoch 87/100\n",
      " - 1s - loss: 1.7784 - accuracy: 0.3764\n",
      "Epoch 88/100\n",
      " - 1s - loss: 1.7760 - accuracy: 0.3804\n",
      "Epoch 89/100\n",
      " - 1s - loss: 1.7759 - accuracy: 0.3783\n",
      "Epoch 90/100\n",
      " - 1s - loss: 1.7692 - accuracy: 0.3832\n",
      "Epoch 91/100\n",
      " - 1s - loss: 1.7632 - accuracy: 0.3876\n",
      "Epoch 92/100\n",
      " - 1s - loss: 1.7610 - accuracy: 0.3863\n",
      "Epoch 93/100\n",
      " - 1s - loss: 1.7532 - accuracy: 0.3893\n",
      "Epoch 94/100\n",
      " - 1s - loss: 1.7529 - accuracy: 0.3864\n",
      "Epoch 95/100\n",
      " - 1s - loss: 1.7527 - accuracy: 0.3820\n",
      "Epoch 96/100\n",
      " - 1s - loss: 1.7391 - accuracy: 0.3913\n",
      "Epoch 97/100\n",
      " - 1s - loss: 1.7426 - accuracy: 0.3890\n",
      "Epoch 98/100\n",
      " - 1s - loss: 1.7367 - accuracy: 0.3921\n",
      "Epoch 99/100\n",
      " - 1s - loss: 1.7281 - accuracy: 0.3953\n",
      "Epoch 100/100\n",
      " - 1s - loss: 1.7271 - accuracy: 0.3944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x135846cf8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=16, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train_categorical, epochs=100, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6405672850065818, Accuracy: 0.1834947019815445\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test for I vs. E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 0.5498 - accuracy: 0.7628\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.5390 - accuracy: 0.7650\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.5346 - accuracy: 0.7658\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5313 - accuracy: 0.7671\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.5289 - accuracy: 0.7665\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.5292 - accuracy: 0.7673\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5262 - accuracy: 0.7665\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5270 - accuracy: 0.7674\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.5246 - accuracy: 0.7678\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.5232 - accuracy: 0.7673\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.5213 - accuracy: 0.7679\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.5214 - accuracy: 0.7678\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.5173 - accuracy: 0.7704\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.5167 - accuracy: 0.7691\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.5138 - accuracy: 0.7702\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.5116 - accuracy: 0.7698\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.5116 - accuracy: 0.7731\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.5074 - accuracy: 0.7734\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.5065 - accuracy: 0.7733\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.5061 - accuracy: 0.7725\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.5012 - accuracy: 0.7751\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.4989 - accuracy: 0.7747\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.4975 - accuracy: 0.7756\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.4937 - accuracy: 0.7771\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.4902 - accuracy: 0.7790\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.4889 - accuracy: 0.7765\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.4880 - accuracy: 0.7814\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.4811 - accuracy: 0.7834\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.4813 - accuracy: 0.7827\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.4768 - accuracy: 0.7825\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.4737 - accuracy: 0.7862\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.4716 - accuracy: 0.7859\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.4691 - accuracy: 0.7891\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.4629 - accuracy: 0.7925\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.4615 - accuracy: 0.7925\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.4595 - accuracy: 0.7922\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.4573 - accuracy: 0.7956\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.4519 - accuracy: 0.7982\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.4508 - accuracy: 0.7976\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.4504 - accuracy: 0.7983\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.4435 - accuracy: 0.8046\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.4406 - accuracy: 0.8048\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.4375 - accuracy: 0.8051\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.4336 - accuracy: 0.8079\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.4326 - accuracy: 0.8077\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.4273 - accuracy: 0.8100\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.4237 - accuracy: 0.8139\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.4227 - accuracy: 0.8091\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.4184 - accuracy: 0.8129\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.4168 - accuracy: 0.8148\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.4147 - accuracy: 0.8174\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.4093 - accuracy: 0.8209\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.4079 - accuracy: 0.8192\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.4047 - accuracy: 0.8222\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3990 - accuracy: 0.8263\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.4032 - accuracy: 0.8239\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3979 - accuracy: 0.8274\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3923 - accuracy: 0.8277\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3903 - accuracy: 0.8318\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3875 - accuracy: 0.8292\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3809 - accuracy: 0.8334\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3777 - accuracy: 0.8369\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3819 - accuracy: 0.8362\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3799 - accuracy: 0.8337\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3703 - accuracy: 0.8354\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3701 - accuracy: 0.8426\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3644 - accuracy: 0.8472\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3646 - accuracy: 0.8391\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3588 - accuracy: 0.8435\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3556 - accuracy: 0.8474\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3571 - accuracy: 0.8495\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3519 - accuracy: 0.8466\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3463 - accuracy: 0.8531\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3463 - accuracy: 0.8508\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3447 - accuracy: 0.8509\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3365 - accuracy: 0.8564\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3374 - accuracy: 0.8580\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3354 - accuracy: 0.8554\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3305 - accuracy: 0.8609\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3289 - accuracy: 0.8597\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3279 - accuracy: 0.8603\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3283 - accuracy: 0.8566\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3236 - accuracy: 0.8618\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3200 - accuracy: 0.8650\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3205 - accuracy: 0.8661\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3110 - accuracy: 0.8681\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3125 - accuracy: 0.8698\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3126 - accuracy: 0.8707\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3067 - accuracy: 0.8732\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3024 - accuracy: 0.8729\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2997 - accuracy: 0.8781\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2968 - accuracy: 0.8769\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2931 - accuracy: 0.8793\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2929 - accuracy: 0.8769\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.2899 - accuracy: 0.8777\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2864 - accuracy: 0.8801\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.2835 - accuracy: 0.8852\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.2870 - accuracy: 0.8801\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.2792 - accuracy: 0.8887\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.2744 - accuracy: 0.8904\n",
      "I vs. E - Loss: 0.85585678670746, Accuracy: 0.6887966990470886\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "target = mbti_df[\"i_e\"]\n",
    "target_names = [\"Introvert\",\"Extrovert\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled1 = X_scaler.transform(X_train)\n",
    "X_test_scaled1 = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical1 = to_categorical(encoded_y_train)\n",
    "y_test_categorical1 = to_categorical(encoded_y_test)\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model1.add(Dense(units=100, activation='relu'))\n",
    "model1.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model1.fit(X_train_scaled1, y_train_categorical1, epochs=100, shuffle=True, verbose=2)\n",
    "\n",
    "model_loss, model_accuracy = model1.evaluate(X_test_scaled1, y_test_categorical1, verbose=2)\n",
    "print(f\"I vs. E - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Batch Size and Number of Epochs\n",
    "def create_model(init_mode='uniform'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "model_CV1 = KerasClassifier(build_fn=create_model,verbose=2)\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid1 = GridSearchCV(model_CV1, param_grid, n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss: 0.5547 - accuracy: 0.7611\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.5387 - accuracy: 0.7664\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.5350 - accuracy: 0.7661\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.5328 - accuracy: 0.7671\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.5331 - accuracy: 0.7648\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.5289 - accuracy: 0.7665\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.5303 - accuracy: 0.7659\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.5258 - accuracy: 0.7668\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.5266 - accuracy: 0.7664\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.5249 - accuracy: 0.7679\n",
      "Best: 0.763449 using {'batch_size': 100, 'epochs': 10}\n",
      "0.759453 (0.004906) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.708116 (0.010800) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.673840 (0.011924) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.761605 (0.007682) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.726253 (0.004098) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.670765 (0.012880) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.761758 (0.006669) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.725484 (0.012136) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.684906 (0.002558) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.761605 (0.009107) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.740701 (0.003127) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.695973 (0.005915) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.761144 (0.008434) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.738242 (0.011006) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.708730 (0.010837) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.763449 (0.005692) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.744082 (0.003587) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.704273 (0.003034) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "grid_result1=grid1.fit(X_train_scaled1, y_train_categorical1)\n",
    "print(\"Best: %f using %s\" % (grid_result1.best_score_, grid_result1.best_params_))\n",
    "means = grid_result1.cv_results_['mean_test_score']\n",
    "stds = grid_result1.cv_results_['std_test_score']\n",
    "params = grid_result1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 0s - loss: 0.6193 - accuracy: 0.6835\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.5499 - accuracy: 0.7654\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.5445 - accuracy: 0.7654\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.5417 - accuracy: 0.7654\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.5395 - accuracy: 0.7654\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.5380 - accuracy: 0.7656\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.5368 - accuracy: 0.7659\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.5359 - accuracy: 0.7661\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.5351 - accuracy: 0.7661\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.5346 - accuracy: 0.7664\n",
      "Best: 0.765447 using {'optimizer': 'SGD'}\n",
      "0.765447 (0.004649) with: {'optimizer': 'SGD'}\n",
      "0.762220 (0.008338) with: {'optimizer': 'RMSprop'}\n",
      "0.764371 (0.006943) with: {'optimizer': 'Adagrad'}\n",
      "0.763142 (0.005585) with: {'optimizer': 'Adadelta'}\n",
      "0.761605 (0.008575) with: {'optimizer': 'Adam'}\n",
      "0.764064 (0.006306) with: {'optimizer': 'Adamax'}\n",
      "0.762527 (0.004110) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# Tune the Training Optimization Algorithm\n",
    "def create_model1(optimizer='adam'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "model_CV2 = KerasClassifier(build_fn=create_model1, epochs=10, batch_size=100, verbose=2)\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid1 = dict(optimizer=optimizer)\n",
    "grid2 = GridSearchCV(estimator=model_CV2, param_grid=param_grid1, n_jobs=-1, cv=3)\n",
    "grid_result2 = grid2.fit(X_train_scaled1, y_train_categorical1)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result2.best_score_, grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 0s - loss: 0.6310 - accuracy: 0.6846\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.5627 - accuracy: 0.7642\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.5463 - accuracy: 0.7650\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.5408 - accuracy: 0.7653\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.5385 - accuracy: 0.7658\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.5374 - accuracy: 0.7661\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.5366 - accuracy: 0.7662\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.5362 - accuracy: 0.7658\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.5359 - accuracy: 0.7662\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.5358 - accuracy: 0.7664\n",
      "Best: 0.766523 using {'activation': 'softsign'}\n",
      "0.765447 (0.004785) with: {'activation': 'softmax'}\n",
      "0.765447 (0.004649) with: {'activation': 'softplus'}\n",
      "0.766523 (0.004031) with: {'activation': 'softsign'}\n",
      "0.765140 (0.004815) with: {'activation': 'relu'}\n",
      "0.766370 (0.004949) with: {'activation': 'tanh'}\n",
      "0.765447 (0.004785) with: {'activation': 'sigmoid'}\n",
      "0.765447 (0.004785) with: {'activation': 'hard_sigmoid'}\n",
      "0.765601 (0.005441) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Tune the Neuron Activation Function\n",
    "def create_model2(activation='relu'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation=activation, input_dim=11))\n",
    "    model.add(Dense(units=100, activation=activation))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer='SGD',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "model_CV3 = KerasClassifier(build_fn=create_model2, epochs=10, batch_size=100, verbose=2)\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid2 = dict(activation=activation)\n",
    "grid3 = GridSearchCV(estimator=model_CV3, param_grid=param_grid2, n_jobs=-1, cv=3)\n",
    "\n",
    "grid_result3 = grid3.fit(X_train_scaled1, y_train_categorical1)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result3.best_score_, grid_result3.best_params_))\n",
    "means = grid_result3.cv_results_['mean_test_score']\n",
    "stds = grid_result3.cv_results_['std_test_score']\n",
    "params = grid_result3.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Introvert       0.73      0.02      0.03       473\n",
      "   Extrovert       0.78      1.00      0.88      1696\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      2169\n",
      "   macro avg       0.76      0.51      0.46      2169\n",
      "weighted avg       0.77      0.78      0.69      2169\n",
      " samples avg       0.78      0.78      0.78      2169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = grid3.predict(X_test_scaled1)\n",
    "predictions=to_categorical(predictions)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_categorical1, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss: 0.6212 - accuracy: 0.7153\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.5597 - accuracy: 0.7631\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.5448 - accuracy: 0.7662\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.5395 - accuracy: 0.7659\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.5377 - accuracy: 0.7659\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.5371 - accuracy: 0.7662\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.5368 - accuracy: 0.7662\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.5366 - accuracy: 0.7661\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.5364 - accuracy: 0.7661\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.5363 - accuracy: 0.7659\n",
      "I vs. E - Loss: 0.5181894626360216, Accuracy: 0.7828492522239685\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(units=100, activation='softsign', input_dim=11))\n",
    "model1.add(Dense(units=100, activation='softsign'))\n",
    "model1.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model1.compile(\n",
    "    optimizer='SGD',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model1.fit(X_train_scaled1, y_train_categorical1, batch_size=100, epochs=10, shuffle=True, verbose=2)\n",
    "\n",
    "model_loss, model_accuracy = model1.evaluate(X_test_scaled1, y_test_categorical1, verbose=2)\n",
    "print(f\"I vs. E - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('Models/NN_ie.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test for N vs. S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 0.4255 - accuracy: 0.8560\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.4029 - accuracy: 0.8632\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.3975 - accuracy: 0.8632\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3942 - accuracy: 0.8634\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3928 - accuracy: 0.8630\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3908 - accuracy: 0.8634\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3904 - accuracy: 0.8632\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.3895 - accuracy: 0.8635\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3866 - accuracy: 0.8632\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.3870 - accuracy: 0.8630\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.3853 - accuracy: 0.8632\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3839 - accuracy: 0.8637\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.3833 - accuracy: 0.8632\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3812 - accuracy: 0.8632\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3799 - accuracy: 0.8634\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.3787 - accuracy: 0.8632\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.3767 - accuracy: 0.8638\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.3756 - accuracy: 0.8632\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.3730 - accuracy: 0.8635\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3702 - accuracy: 0.8640\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3692 - accuracy: 0.8644\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3682 - accuracy: 0.8647\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3654 - accuracy: 0.8644\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3628 - accuracy: 0.8658\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3621 - accuracy: 0.8666\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3598 - accuracy: 0.8652\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3587 - accuracy: 0.8670\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3547 - accuracy: 0.8666\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3551 - accuracy: 0.8674\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3502 - accuracy: 0.8684\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3492 - accuracy: 0.8678\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3471 - accuracy: 0.8695\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3449 - accuracy: 0.8690\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3425 - accuracy: 0.8695\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3410 - accuracy: 0.8701\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3372 - accuracy: 0.8707\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3348 - accuracy: 0.8703\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3340 - accuracy: 0.8715\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3296 - accuracy: 0.8732\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3282 - accuracy: 0.8724\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3282 - accuracy: 0.8709\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3218 - accuracy: 0.8749\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3210 - accuracy: 0.8755\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3206 - accuracy: 0.8766\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3174 - accuracy: 0.8763\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3137 - accuracy: 0.8761\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3095 - accuracy: 0.8793\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3076 - accuracy: 0.8775\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3075 - accuracy: 0.8789\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3039 - accuracy: 0.8796\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3022 - accuracy: 0.8792\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3019 - accuracy: 0.8818\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.2963 - accuracy: 0.8795\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.2935 - accuracy: 0.8855\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.2889 - accuracy: 0.8855\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.2888 - accuracy: 0.8864\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.2849 - accuracy: 0.8867\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.2829 - accuracy: 0.8896\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.2802 - accuracy: 0.8899\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.2771 - accuracy: 0.8878\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.2761 - accuracy: 0.8875\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.2746 - accuracy: 0.8909\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.2697 - accuracy: 0.8927\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.2732 - accuracy: 0.8924\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.2681 - accuracy: 0.8929\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.2658 - accuracy: 0.8950\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.2614 - accuracy: 0.8961\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.2591 - accuracy: 0.8986\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.2592 - accuracy: 0.8992\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.2560 - accuracy: 0.9018\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.2533 - accuracy: 0.9004\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.2505 - accuracy: 0.8999\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.2494 - accuracy: 0.9041\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.2437 - accuracy: 0.9026\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.2438 - accuracy: 0.9055\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.2400 - accuracy: 0.9055\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.2374 - accuracy: 0.9049\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.2369 - accuracy: 0.9076\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.2340 - accuracy: 0.9053\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.2358 - accuracy: 0.9072\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.2306 - accuracy: 0.9076\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.2326 - accuracy: 0.9104\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.2201 - accuracy: 0.9135\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.2260 - accuracy: 0.9130\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.2215 - accuracy: 0.9113\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.2187 - accuracy: 0.9161\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.2174 - accuracy: 0.9142\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.2144 - accuracy: 0.9175\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.2132 - accuracy: 0.9187\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.2115 - accuracy: 0.9208\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.2096 - accuracy: 0.9168\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.2077 - accuracy: 0.9196\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.2029 - accuracy: 0.9185\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.2031 - accuracy: 0.9215\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.1973 - accuracy: 0.9235\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.1990 - accuracy: 0.9210\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.1954 - accuracy: 0.9242\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.1905 - accuracy: 0.9281\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.1997 - accuracy: 0.9235\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.1922 - accuracy: 0.9270\n",
      "N vs. S - Loss: 0.7160896583326735, Accuracy: 0.8105117678642273\n"
     ]
    }
   ],
   "source": [
    "target = mbti_df[\"n_s\"]\n",
    "target_names = [\"Intuition\",\"Sensing\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled2 = X_scaler.transform(X_train)\n",
    "X_test_scaled2 = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical2 = to_categorical(encoded_y_train)\n",
    "y_test_categorical2 = to_categorical(encoded_y_test)\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model2.add(Dense(units=100, activation='relu'))\n",
    "model2.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model2.fit(X_train_scaled2, y_train_categorical2, epochs=100, shuffle=True, verbose=2)\n",
    "\n",
    "model_loss, model_accuracy = model2.evaluate(X_test_scaled2, y_test_categorical2, verbose=2)\n",
    "print(f\"N vs. S - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Batch Size and Number of Epochs\n",
    "def create_model(init_mode='uniform'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "model_CV1 = KerasClassifier(build_fn=create_model,verbose=2)\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid1 = GridSearchCV(model_CV1, param_grid, n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss: 0.4396 - accuracy: 0.8552\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.4067 - accuracy: 0.8632\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4000 - accuracy: 0.8632\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.3970 - accuracy: 0.8630\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.3942 - accuracy: 0.8632\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.3917 - accuracy: 0.8635\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.3912 - accuracy: 0.8632\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.3896 - accuracy: 0.8634\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.3864 - accuracy: 0.8635\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.3862 - accuracy: 0.8635\n",
      "Best: 0.863203 using {'batch_size': 80, 'epochs': 10}\n",
      "0.862588 (0.003008) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.831694 (0.002876) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.802644 (0.012212) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.862896 (0.003084) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.835383 (0.003457) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.797571 (0.017496) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.862281 (0.003825) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.850753 (0.009098) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.812173 (0.010329) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.862896 (0.003084) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.845681 (0.008316) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.815094 (0.014306) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.863203 (0.002841) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.852751 (0.001157) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.834768 (0.001558) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.863203 (0.002841) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.859053 (0.001892) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.823701 (0.016851) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "grid_result1=grid1.fit(X_train_scaled2, y_train_categorical2)\n",
    "print(\"Best: %f using %s\" % (grid_result1.best_score_, grid_result1.best_params_))\n",
    "means = grid_result1.cv_results_['mean_test_score']\n",
    "stds = grid_result1.cv_results_['std_test_score']\n",
    "params = grid_result1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss: 0.5017 - accuracy: 0.8140\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.4259 - accuracy: 0.8632\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4181 - accuracy: 0.8632\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.4134 - accuracy: 0.8632\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.4100 - accuracy: 0.8632\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.4074 - accuracy: 0.8632\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.4052 - accuracy: 0.8632\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.4037 - accuracy: 0.8632\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.4025 - accuracy: 0.8632\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.4015 - accuracy: 0.8632\n",
      "Best: 0.863203 using {'optimizer': 'SGD'}\n",
      "0.863203 (0.002841) with: {'optimizer': 'SGD'}\n",
      "0.863049 (0.002957) with: {'optimizer': 'RMSprop'}\n",
      "0.862742 (0.002869) with: {'optimizer': 'Adagrad'}\n",
      "0.863203 (0.002841) with: {'optimizer': 'Adadelta'}\n",
      "0.862896 (0.003084) with: {'optimizer': 'Adam'}\n",
      "0.862896 (0.003084) with: {'optimizer': 'Adamax'}\n",
      "0.859514 (0.005986) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# Tune the Training Optimization Algorithm\n",
    "def create_model1(optimizer='adam'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "model_CV2 = KerasClassifier(build_fn=create_model1, epochs=10, batch_size=80, verbose=2)\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid1 = dict(optimizer=optimizer)\n",
    "grid2 = GridSearchCV(estimator=model_CV2, param_grid=param_grid1, n_jobs=-1, cv=3)\n",
    "grid_result2 = grid2.fit(X_train_scaled2, y_train_categorical2)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result2.best_score_, grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss: 0.6015 - accuracy: 0.8632\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.5022 - accuracy: 0.8632\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4553 - accuracy: 0.8632\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.4312 - accuracy: 0.8632\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.4184 - accuracy: 0.8632\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.4108 - accuracy: 0.8632\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.4064 - accuracy: 0.8632\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.4038 - accuracy: 0.8632\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.4021 - accuracy: 0.8632\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.4010 - accuracy: 0.8632\n",
      "Best: 0.863203 using {'activation': 'softmax'}\n",
      "0.863203 (0.002841) with: {'activation': 'softmax'}\n",
      "0.863203 (0.002841) with: {'activation': 'softplus'}\n",
      "0.863203 (0.002841) with: {'activation': 'softsign'}\n",
      "0.863203 (0.002841) with: {'activation': 'relu'}\n",
      "0.863203 (0.002841) with: {'activation': 'tanh'}\n",
      "0.863203 (0.002841) with: {'activation': 'sigmoid'}\n",
      "0.863203 (0.002841) with: {'activation': 'hard_sigmoid'}\n",
      "0.863203 (0.002841) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Tune the Neuron Activation Function\n",
    "def create_model2(activation='relu'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation=activation, input_dim=11))\n",
    "    model.add(Dense(units=100, activation=activation))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer='SGD',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "model_CV3 = KerasClassifier(build_fn=create_model2, epochs=10, batch_size=80, verbose=2)\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid2 = dict(activation=activation)\n",
    "grid3 = GridSearchCV(estimator=model_CV3, param_grid=param_grid2, n_jobs=-1, cv=3)\n",
    "\n",
    "grid_result3 = grid3.fit(X_train_scaled2, y_train_categorical2)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result3.best_score_, grid_result3.best_params_))\n",
    "means = grid_result3.cv_results_['mean_test_score']\n",
    "stds = grid_result3.cv_results_['std_test_score']\n",
    "params = grid_result3.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss: 0.6123 - accuracy: 0.8438\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.5072 - accuracy: 0.8632\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4579 - accuracy: 0.8632\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.4327 - accuracy: 0.8632\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.4192 - accuracy: 0.8632\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.4113 - accuracy: 0.8632\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.4068 - accuracy: 0.8632\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.4041 - accuracy: 0.8632\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.4023 - accuracy: 0.8632\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.4012 - accuracy: 0.8632\n",
      "N vs. S - Loss: 0.4087249850446368, Accuracy: 0.8584601283073425\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(units=100, activation='softmax', input_dim=11))\n",
    "model2.add(Dense(units=100, activation='softmax'))\n",
    "model2.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model2.compile(\n",
    "    optimizer='SGD',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model2.fit(X_train_scaled2, y_train_categorical2, batch_size=80, epochs=10, shuffle=True, verbose=2)\n",
    "\n",
    "model_loss, model_accuracy = model2.evaluate(X_test_scaled2, y_test_categorical2, verbose=2)\n",
    "print(f\"N vs. S - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('Models/NN_ns.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test for F vs. J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 0.6677 - accuracy: 0.5941\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6549 - accuracy: 0.6111\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.6510 - accuracy: 0.6148\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.6498 - accuracy: 0.6134\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.6454 - accuracy: 0.6190\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6411 - accuracy: 0.6251\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.6413 - accuracy: 0.6290\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.6414 - accuracy: 0.6190\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.6355 - accuracy: 0.6280\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.6350 - accuracy: 0.6360\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.6327 - accuracy: 0.6314\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.6309 - accuracy: 0.6397\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.6303 - accuracy: 0.6402\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.6269 - accuracy: 0.6339\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.6257 - accuracy: 0.6425\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.6233 - accuracy: 0.6480\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.6212 - accuracy: 0.6434\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.6199 - accuracy: 0.6488\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.6186 - accuracy: 0.6505\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.6170 - accuracy: 0.6503\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.6131 - accuracy: 0.6552\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.6113 - accuracy: 0.6542\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.6075 - accuracy: 0.6605\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.6068 - accuracy: 0.6585\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.6036 - accuracy: 0.6678\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.6013 - accuracy: 0.6663\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.5971 - accuracy: 0.6689\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.5982 - accuracy: 0.6695\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.5931 - accuracy: 0.6735\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.5926 - accuracy: 0.6754\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.5880 - accuracy: 0.6766\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.5848 - accuracy: 0.6858\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.5828 - accuracy: 0.6866\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.5772 - accuracy: 0.6911\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.5779 - accuracy: 0.6877\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.5754 - accuracy: 0.6949\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.5719 - accuracy: 0.6961\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.5679 - accuracy: 0.6969\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.5647 - accuracy: 0.6958\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.5629 - accuracy: 0.7035\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.5586 - accuracy: 0.7061\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.5565 - accuracy: 0.7064\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.5541 - accuracy: 0.7063\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.5480 - accuracy: 0.7127\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.5478 - accuracy: 0.7129\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.5453 - accuracy: 0.7178\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.5426 - accuracy: 0.7167\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.5400 - accuracy: 0.7200\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.5346 - accuracy: 0.7238\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.5341 - accuracy: 0.7224\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.5281 - accuracy: 0.7289\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.5248 - accuracy: 0.7336\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.5212 - accuracy: 0.7336\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.5185 - accuracy: 0.7404\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.5152 - accuracy: 0.7393\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.5132 - accuracy: 0.7453\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.5091 - accuracy: 0.7456\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.5051 - accuracy: 0.7435\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.5031 - accuracy: 0.7521\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.5033 - accuracy: 0.7493\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.4962 - accuracy: 0.7535\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.4948 - accuracy: 0.7538\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.4907 - accuracy: 0.7622\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.4849 - accuracy: 0.7585\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.4808 - accuracy: 0.7644\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.4788 - accuracy: 0.7638\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.4763 - accuracy: 0.7727\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.4728 - accuracy: 0.7684\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.4716 - accuracy: 0.7731\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.4644 - accuracy: 0.7748\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.4639 - accuracy: 0.7744\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.4566 - accuracy: 0.7830\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.4589 - accuracy: 0.7813\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.4546 - accuracy: 0.7879\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.4508 - accuracy: 0.7879\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.4457 - accuracy: 0.7851\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.4408 - accuracy: 0.7882\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.4384 - accuracy: 0.7920\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.4408 - accuracy: 0.7916\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.4329 - accuracy: 0.7979\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.4346 - accuracy: 0.7923\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.4259 - accuracy: 0.8022\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.4250 - accuracy: 0.8016\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.4204 - accuracy: 0.8056\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.4158 - accuracy: 0.8051\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.4128 - accuracy: 0.8102\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.4131 - accuracy: 0.8053\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.4087 - accuracy: 0.8077\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.4065 - accuracy: 0.8122\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.4019 - accuracy: 0.8122\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.4015 - accuracy: 0.8183\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3958 - accuracy: 0.8180\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3965 - accuracy: 0.8180\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3922 - accuracy: 0.8180\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3856 - accuracy: 0.8266\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3838 - accuracy: 0.8265\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3797 - accuracy: 0.8275\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3764 - accuracy: 0.8300\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3761 - accuracy: 0.8271\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3737 - accuracy: 0.8331\n",
      "F vs. J - Loss: 0.9752376229601447, Accuracy: 0.5569387078285217\n"
     ]
    }
   ],
   "source": [
    "target = mbti_df[\"f_t\"]\n",
    "target_names = [\"Feeling\",\"Thinking\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled3 = X_scaler.transform(X_train)\n",
    "X_test_scaled3 = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical3 = to_categorical(encoded_y_train)\n",
    "y_test_categorical3 = to_categorical(encoded_y_test)\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model3.add(Dense(units=100, activation='relu'))\n",
    "model3.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model3.fit(X_train_scaled3, y_train_categorical3, epochs=100, shuffle=True, verbose=2)\n",
    "\n",
    "model_loss, model_accuracy = model3.evaluate(X_test_scaled3, y_test_categorical3, verbose=2)\n",
    "print(f\"F vs. T - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Batch Size and Number of Epochs\n",
    "def create_model(init_mode='uniform'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "model_CV1 = KerasClassifier(build_fn=create_model,verbose=2)\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid1 = GridSearchCV(model_CV1, param_grid, n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss: 0.6684 - accuracy: 0.5868\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6555 - accuracy: 0.6091\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.6514 - accuracy: 0.6147\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6508 - accuracy: 0.6088\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6478 - accuracy: 0.6105\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6466 - accuracy: 0.6214\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.6475 - accuracy: 0.6137\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.6434 - accuracy: 0.6200\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.6410 - accuracy: 0.6257\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.6385 - accuracy: 0.6280\n",
      "Best: 0.601137 using {'batch_size': 100, 'epochs': 10}\n",
      "0.600523 (0.004772) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.563326 (0.013165) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.559637 (0.007269) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.599293 (0.008580) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.567169 (0.002688) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.554872 (0.004981) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.600830 (0.006967) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.579465 (0.006050) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.545035 (0.006537) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.594836 (0.008879) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.566400 (0.009600) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.567015 (0.006304) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.600984 (0.013180) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.579465 (0.011610) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.561021 (0.008442) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.601137 (0.006153) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.584537 (0.003168) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.563019 (0.007172) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "grid_result1=grid1.fit(X_train_scaled3, y_train_categorical3)\n",
    "print(\"Best: %f using %s\" % (grid_result1.best_score_, grid_result1.best_params_))\n",
    "means = grid_result1.cv_results_['mean_test_score']\n",
    "stds = grid_result1.cv_results_['std_test_score']\n",
    "params = grid_result1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 0s - loss: 0.6770 - accuracy: 0.5808\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6556 - accuracy: 0.6085\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.6516 - accuracy: 0.6130\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6486 - accuracy: 0.6199\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6458 - accuracy: 0.6197\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6432 - accuracy: 0.6253\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.6423 - accuracy: 0.6236\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.6410 - accuracy: 0.6260\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.6410 - accuracy: 0.6242\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.6388 - accuracy: 0.6290\n",
      "Best: 0.606671 using {'optimizer': 'Adagrad'}\n",
      "0.587611 (0.011876) with: {'optimizer': 'SGD'}\n",
      "0.595604 (0.006766) with: {'optimizer': 'RMSprop'}\n",
      "0.606671 (0.011108) with: {'optimizer': 'Adagrad'}\n",
      "0.593760 (0.000678) with: {'optimizer': 'Adadelta'}\n",
      "0.601752 (0.003428) with: {'optimizer': 'Adam'}\n",
      "0.602521 (0.006442) with: {'optimizer': 'Adamax'}\n",
      "0.588841 (0.007016) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# Tune the Training Optimization Algorithm\n",
    "def create_model1(optimizer='adam'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "model_CV2 = KerasClassifier(build_fn=create_model1, epochs=10, batch_size=100, verbose=2)\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid1 = dict(optimizer=optimizer)\n",
    "grid2 = GridSearchCV(estimator=model_CV2, param_grid=param_grid1, n_jobs=-1, cv=3)\n",
    "grid_result2 = grid2.fit(X_train_scaled3, y_train_categorical3)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result2.best_score_, grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 0s - loss: 0.6743 - accuracy: 0.5931\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6542 - accuracy: 0.6054\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.6497 - accuracy: 0.6090\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6463 - accuracy: 0.6165\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6443 - accuracy: 0.6137\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6435 - accuracy: 0.6263\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.6412 - accuracy: 0.6227\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.6407 - accuracy: 0.6254\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.6392 - accuracy: 0.6257\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.6375 - accuracy: 0.6287\n",
      "Best: 0.608054 using {'activation': 'relu'}\n",
      "0.540271 (0.003805) with: {'activation': 'softmax'}\n",
      "0.606824 (0.017051) with: {'activation': 'softplus'}\n",
      "0.604365 (0.017703) with: {'activation': 'softsign'}\n",
      "0.608054 (0.007418) with: {'activation': 'relu'}\n",
      "0.606978 (0.020915) with: {'activation': 'tanh'}\n",
      "0.593299 (0.014545) with: {'activation': 'sigmoid'}\n",
      "0.597449 (0.016622) with: {'activation': 'hard_sigmoid'}\n",
      "0.593760 (0.011485) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Tune the Neuron Activation Function\n",
    "def create_model2(activation='relu'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation=activation, input_dim=11))\n",
    "    model.add(Dense(units=100, activation=activation))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer='Adagrad',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "model_CV3 = KerasClassifier(build_fn=create_model2, epochs=10, batch_size=100, verbose=2)\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid2 = dict(activation=activation)\n",
    "grid3 = GridSearchCV(estimator=model_CV3, param_grid=param_grid2, n_jobs=-1, cv=3)\n",
    "\n",
    "grid_result3 = grid3.fit(X_train_scaled3, y_train_categorical3)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result3.best_score_, grid_result3.best_params_))\n",
    "means = grid_result3.cv_results_['mean_test_score']\n",
    "stds = grid_result3.cv_results_['std_test_score']\n",
    "params = grid_result3.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 0s - loss: 0.6714 - accuracy: 0.5915\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6531 - accuracy: 0.6053\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.6497 - accuracy: 0.6159\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6469 - accuracy: 0.6223\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6443 - accuracy: 0.6242\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6423 - accuracy: 0.6293\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.6412 - accuracy: 0.6254\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.6401 - accuracy: 0.6257\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.6399 - accuracy: 0.6288\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.6378 - accuracy: 0.6306\n",
      "F vs. T - Loss: 0.6595578840274644, Accuracy: 0.6067312359809875\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model3.add(Dense(units=100, activation='relu'))\n",
    "model3.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model3.compile(\n",
    "    optimizer='Adagrad',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model3.fit(X_train_scaled3, y_train_categorical3, batch_size=100, epochs=10, shuffle=True, verbose=2)\n",
    "\n",
    "model_loss, model_accuracy = model3.evaluate(X_test_scaled3, y_test_categorical3, verbose=2)\n",
    "print(f\"F vs. T - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('Models/NN_ft.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-test for J vs. P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 0.6782 - accuracy: 0.5959\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6714 - accuracy: 0.5951\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6690 - accuracy: 0.5968\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6665 - accuracy: 0.6031\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.6658 - accuracy: 0.6008\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.6650 - accuracy: 0.6044\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.6626 - accuracy: 0.6076\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.6608 - accuracy: 0.6048\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.6604 - accuracy: 0.6084\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.6593 - accuracy: 0.6107\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.6577 - accuracy: 0.6111\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.6551 - accuracy: 0.6187\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.6530 - accuracy: 0.6190\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.6514 - accuracy: 0.6190\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.6497 - accuracy: 0.6228\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.6483 - accuracy: 0.6234\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.6442 - accuracy: 0.6267\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.6443 - accuracy: 0.6320\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.6401 - accuracy: 0.6336\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.6400 - accuracy: 0.6333\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.6342 - accuracy: 0.6389\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.6316 - accuracy: 0.6459\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.6293 - accuracy: 0.6454\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.6260 - accuracy: 0.6476\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.6225 - accuracy: 0.6480\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.6193 - accuracy: 0.6568\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.6150 - accuracy: 0.6589\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.6116 - accuracy: 0.6646\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.6142 - accuracy: 0.6585\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.6055 - accuracy: 0.6674\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.6007 - accuracy: 0.6771\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.5980 - accuracy: 0.6735\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.5944 - accuracy: 0.6818\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.5914 - accuracy: 0.6781\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.5883 - accuracy: 0.6869\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.5844 - accuracy: 0.6904\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.5801 - accuracy: 0.6904\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.5774 - accuracy: 0.6983\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.5736 - accuracy: 0.6980\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.5694 - accuracy: 0.7050\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.5656 - accuracy: 0.7070\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.5611 - accuracy: 0.7024\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.5598 - accuracy: 0.7089\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.5530 - accuracy: 0.7160\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.5498 - accuracy: 0.7181\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.5454 - accuracy: 0.7227\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.5438 - accuracy: 0.7249\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.5379 - accuracy: 0.7295\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.5357 - accuracy: 0.7322\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.5323 - accuracy: 0.7272\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.5297 - accuracy: 0.7319\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.5238 - accuracy: 0.7375\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.5182 - accuracy: 0.7412\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.5166 - accuracy: 0.7412\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.5147 - accuracy: 0.7453\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.5076 - accuracy: 0.7502\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.5077 - accuracy: 0.7553\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.5022 - accuracy: 0.7561\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.4966 - accuracy: 0.7624\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.4977 - accuracy: 0.7571\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.4909 - accuracy: 0.7615\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.4849 - accuracy: 0.7673\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.4829 - accuracy: 0.7673\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.4799 - accuracy: 0.7751\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.4770 - accuracy: 0.7748\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.4730 - accuracy: 0.7751\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.4712 - accuracy: 0.7828\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.4647 - accuracy: 0.7797\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.4617 - accuracy: 0.7850\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.4595 - accuracy: 0.7837\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.4539 - accuracy: 0.7877\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.4511 - accuracy: 0.7876\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.4459 - accuracy: 0.8003\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.4444 - accuracy: 0.7933\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.4393 - accuracy: 0.7993\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.4396 - accuracy: 0.7971\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.4326 - accuracy: 0.8019\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.4299 - accuracy: 0.8030\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.4285 - accuracy: 0.8028\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.4224 - accuracy: 0.8074\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.4164 - accuracy: 0.8091\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.4172 - accuracy: 0.8109\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.4127 - accuracy: 0.8180\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.4084 - accuracy: 0.8113\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.4038 - accuracy: 0.8225\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.4014 - accuracy: 0.8235\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3977 - accuracy: 0.8245\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3964 - accuracy: 0.8225\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3940 - accuracy: 0.8237\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3917 - accuracy: 0.8251\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3813 - accuracy: 0.8371\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3846 - accuracy: 0.8355\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3829 - accuracy: 0.8315\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3774 - accuracy: 0.8348\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3730 - accuracy: 0.8363\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.3717 - accuracy: 0.8423\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3672 - accuracy: 0.8423\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3663 - accuracy: 0.8445\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3657 - accuracy: 0.8398\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3574 - accuracy: 0.8428\n",
      "J vs. P - Loss: 1.1251083220573765, Accuracy: 0.5205163955688477\n"
     ]
    }
   ],
   "source": [
    "target = mbti_df[\"j_p\"]\n",
    "target_names = [\"Judging\",\"Perceiving\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, target, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled4 = X_scaler.transform(X_train)\n",
    "X_test_scaled4 = X_scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical4 = to_categorical(encoded_y_train)\n",
    "y_test_categorical4 = to_categorical(encoded_y_test)\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model4.add(Dense(units=100, activation='relu'))\n",
    "model4.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model4.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model4.fit(X_train_scaled4, y_train_categorical4, epochs=100, shuffle=True, verbose=2)\n",
    "\n",
    "model_loss, model_accuracy = model4.evaluate(X_test_scaled4, y_test_categorical4, verbose=2)\n",
    "print(f\"J vs. P - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Batch Size and Number of Epochs\n",
    "def create_model(init_mode='uniform'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "model_CV1 = KerasClassifier(build_fn=create_model,verbose=2)\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid1 = GridSearchCV(model_CV1, param_grid, n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss: 0.6848 - accuracy: 0.5813\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6725 - accuracy: 0.5988\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.6686 - accuracy: 0.6013\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6692 - accuracy: 0.6024\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6679 - accuracy: 0.5988\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6660 - accuracy: 0.6010\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.6654 - accuracy: 0.6019\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.6638 - accuracy: 0.6033\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.6624 - accuracy: 0.6073\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.6622 - accuracy: 0.6030\n",
      "Best: 0.596065 using {'batch_size': 100, 'epochs': 10}\n",
      "0.579311 (0.016284) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.536274 (0.013647) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.533508 (0.006453) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.585613 (0.011352) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.545035 (0.014079) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.529511 (0.012933) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.585613 (0.004257) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.555948 (0.011431) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.546265 (0.006049) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.589148 (0.010016) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.555641 (0.013944) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.539809 (0.011318) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.589610 (0.012999) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.559022 (0.005601) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.538426 (0.018996) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.596065 (0.001028) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.563172 (0.007795) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.560560 (0.018661) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "grid_result1=grid1.fit(X_train_scaled4, y_train_categorical4)\n",
    "print(\"Best: %f using %s\" % (grid_result1.best_score_, grid_result1.best_params_))\n",
    "means = grid_result1.cv_results_['mean_test_score']\n",
    "stds = grid_result1.cv_results_['std_test_score']\n",
    "params = grid_result1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 0s - loss: 0.6768 - accuracy: 0.5936\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6748 - accuracy: 0.6007\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.6736 - accuracy: 0.6025\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6727 - accuracy: 0.6022\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6722 - accuracy: 0.6018\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6716 - accuracy: 0.6019\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.6712 - accuracy: 0.6024\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.6709 - accuracy: 0.6025\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.6705 - accuracy: 0.6024\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.6702 - accuracy: 0.6027\n",
      "Best: 0.601137 using {'optimizer': 'SGD'}\n",
      "0.601137 (0.003553) with: {'optimizer': 'SGD'}\n",
      "0.586228 (0.008644) with: {'optimizer': 'RMSprop'}\n",
      "0.593452 (0.006462) with: {'optimizer': 'Adagrad'}\n",
      "0.574393 (0.003668) with: {'optimizer': 'Adadelta'}\n",
      "0.587765 (0.006600) with: {'optimizer': 'Adam'}\n",
      "0.590993 (0.003518) with: {'optimizer': 'Adamax'}\n",
      "0.578235 (0.015531) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# Tune the Training Optimization Algorithm\n",
    "def create_model1(optimizer='adam'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "model_CV2 = KerasClassifier(build_fn=create_model1, epochs=10, batch_size=100, verbose=2)\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid1 = dict(optimizer=optimizer)\n",
    "grid2 = GridSearchCV(estimator=model_CV2, param_grid=param_grid1, n_jobs=-1, cv=3)\n",
    "grid_result2 = grid2.fit(X_train_scaled4, y_train_categorical4)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result2.best_score_, grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss: 0.6868 - accuracy: 0.6016\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6798 - accuracy: 0.6016\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.6762 - accuracy: 0.6016\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6744 - accuracy: 0.6016\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6734 - accuracy: 0.6016\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6729 - accuracy: 0.6016\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.6727 - accuracy: 0.6016\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.6725 - accuracy: 0.6016\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.6724 - accuracy: 0.6016\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.6724 - accuracy: 0.6016\n",
      "Best: 0.601599 using {'activation': 'softmax'}\n",
      "0.601599 (0.003928) with: {'activation': 'softmax'}\n",
      "0.568398 (0.044231) with: {'activation': 'softplus'}\n",
      "0.599908 (0.005997) with: {'activation': 'softsign'}\n",
      "0.600676 (0.004224) with: {'activation': 'relu'}\n",
      "0.601599 (0.003600) with: {'activation': 'tanh'}\n",
      "0.601599 (0.003928) with: {'activation': 'sigmoid'}\n",
      "0.601599 (0.003928) with: {'activation': 'hard_sigmoid'}\n",
      "0.599754 (0.007584) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Tune the Neuron Activation Function\n",
    "def create_model2(activation='relu'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation=activation, input_dim=11))\n",
    "    model.add(Dense(units=100, activation=activation))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(\n",
    "    optimizer='SGD',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "model_CV3 = KerasClassifier(build_fn=create_model2, epochs=10, batch_size=100, verbose=2)\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid2 = dict(activation=activation)\n",
    "grid3 = GridSearchCV(estimator=model_CV3, param_grid=param_grid2, n_jobs=-1, cv=3)\n",
    "\n",
    "grid_result3 = grid3.fit(X_train_scaled4, y_train_categorical4)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result3.best_score_, grid_result3.best_params_))\n",
    "means = grid_result3.cv_results_['mean_test_score']\n",
    "stds = grid_result3.cv_results_['std_test_score']\n",
    "params = grid_result3.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 0s - loss: 0.6869 - accuracy: 0.6016\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6801 - accuracy: 0.6016\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.6765 - accuracy: 0.6016\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.6745 - accuracy: 0.6016\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.6734 - accuracy: 0.6016\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.6729 - accuracy: 0.6016\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.6727 - accuracy: 0.6016\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.6725 - accuracy: 0.6016\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.6724 - accuracy: 0.6016\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.6724 - accuracy: 0.6016\n",
      "J vs. P - Loss: 0.6683037888899329, Accuracy: 0.6118026971817017\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(units=100, activation='softmax', input_dim=11))\n",
    "model4.add(Dense(units=100, activation='softmax'))\n",
    "model4.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model4.compile(\n",
    "    optimizer='SGD',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model4.fit(X_train_scaled4, y_train_categorical4, batch_size=100, epochs=10, shuffle=True, verbose=2)\n",
    "\n",
    "model_loss, model_accuracy = model4.evaluate(X_test_scaled4, y_test_categorical4, verbose=2)\n",
    "print(f\"J vs. P - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('Models/NN_jp.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "i_e = load_model('Models/NN_ie.h5')\n",
    "n_s = load_model('Models/NN_ns.h5')\n",
    "f_t = load_model('Models/NN_ft.h5')\n",
    "j_p = load_model('Models/NN_jp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test.predict_classes(X_test_scaled1[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_categorical1[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
